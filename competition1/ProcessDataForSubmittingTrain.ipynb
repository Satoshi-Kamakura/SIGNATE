{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理したデータをSageMaker用とローカル用とに作り分ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 出力データ仕様\n",
    "#### 教師データ：訓練用\n",
    "- 目的変数　Y_train.csv　　index, columnあり\n",
    "- 説明変数　X_train.csv　　index, columnあり\n",
    "\n",
    "#### 教師データ：検証用\n",
    "- 目的変数　Y_eval.csv　index, columnあり\n",
    "- 説明変数　X_eval.csv　index, columnあり\n",
    "\n",
    "#### 教師データ：メタデータ  ⇒必要と思ったが、X_eval, Y_evalに含まれるので無しにする\n",
    "- train_meta.csv  id, pj_no, 面積を保持\n",
    "- eval_meta.csv  同上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 SageMaker向けでの処理\n",
    "- データはS3ではなく、ノートブックから直接read_csvできるところに配置する\n",
    "- indexやcolumnはSageMaker上でread_csvするときに必要に応じて無視する\n",
    "- 無視するためには、indexやcolumnsなしでS3へ出力すること\n",
    "- 訓練するときには、入力となる教師データの一列目は目的変数にする必要があるが、SageMaker上のロジックでこのデータを組み立てること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ローカル向け処理\n",
    "- X_train, X_evalは、idとpj_no列をdropしてから、訓練、評価に使う\n",
    "- Y_train, Y_evalは、tanka_pr列を利用する\n",
    "#### 教師データ：訓練用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 共通処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(\"data/processed_train_goto_x.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#　データを分割して出力する\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_eval.to_csv(\"data/X_eval.csv\", index=False)\n",
    "Y_train.to_csv(\"data/Y_train.csv\", index=False)\n",
    "Y_eval.to_csv(\"data/Y_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローカル向け処理。読み込んで学習、検証データと比較してスコアを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv').drop(['id','pj_no'],axis=1)\n",
    "train_y = pd.read_csv('data/Y_train.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.05718676400102\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=400, max_depth=200, min_samples_split=2,n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "model.fit(train_x.values, train_y.values.ravel() )\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.87854701]\n"
     ]
    }
   ],
   "source": [
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)\n",
    "pred_y = model.predict(eval_x.values)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここからSageMaker用のデータを作る処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv')\n",
    "train_y = pd.read_csv('data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.concat([train_y.drop(['id','keiyaku_pr','tc_mseki'],axis=1),train_x.drop(['id','pj_no'],axis=1)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input.to_csv('data/sagemaker_input.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_x = pd.read_csv('data/X_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_x.drop(['id','pj_no'],axis=1).to_csv('data/sagemaker_eval_input.csv',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2_y = pd.read_csv('data/sagemaker_eval_input.csv.out', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.40273999]\n"
     ]
    }
   ],
   "source": [
    "print( mean_absolute_percentage_error(ans_y.values,pred2_y.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
