{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理用のコード 第7版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V6までは、平米あたりの単価を目的変数としていたが、土地の価格を直接目的変数にする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_list( df,cols ):\n",
    "    names = set()\n",
    "    for col in cols:\n",
    "        for i in range(len(df)):\n",
    "            name = df.at[i,col]\n",
    "            if ( type(name) != float ):\n",
    "                names.add(name)\n",
    "    return sorted(list(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_genba(genba, hokakisei_cols):\n",
    "    df = genba.copy()\n",
    "    \n",
    "    # jukyoは使用しないのでを削除\n",
    "    df = df.drop('jukyo',axis=1)\n",
    "    \n",
    "    # 地積公募値には欠損あり(chiseki_kb_hb)\n",
    "    # 実測値で補完する\n",
    "    df['chiseki_kb_hb'] = df['chiseki_kb_hb'].fillna(-99)\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'chiseki_kb_hb'] == -99 ):      \n",
    "            df.at[i,'chiseki_kb_hb'] = df.at[i,'chiseki_js_hb']\n",
    "    \n",
    "    # 地積の公募値と実測値の差を特徴量に追加\n",
    "    df['chiseki_diff'] = df['chiseki_kb_hb']-df['chiseki_js_hb']\n",
    "    \n",
    "    # 二つの用途から、一つの用途、建ぺい率、容積率を返却する\n",
    "    # yotoはダミー変数化する\n",
    "    df[['yoto','kempei','yoseki']] = df.apply(select_yoto, axis=1)\n",
    "    df = pd.merge(df, pd.get_dummies(df[['yoto']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # 上水種別を数値化\n",
    "    df['josui'] = df.apply(lambda x: 1 if x['josui']=='公営' else 0, axis=1)\n",
    "    \n",
    "    # 下水種別を数値化\n",
    "    df['gesui'] = df.apply(lambda x: 1 if x['gesui']=='公共下水' else 0, axis=1)\n",
    "    \n",
    "    # ガス種別を数値化\n",
    "    # df['gas'] = df.apply(lambda x: 2 if x['gas'] =='都市ガス' else 1 if x['gas'] == '集中プロパン' else 0, axis=1)\n",
    "    \n",
    "    # ガスをダミー変数化\n",
    "    df = pd.merge(df, pd.get_dummies(df[['gas']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # 雨水（usui）をダミー変数化\n",
    "    df = pd.merge(df, pd.get_dummies(df[['usui']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # 欠損値処理\n",
    "    # 建て売り数 0で補完（trainデータのID:726は、一件だけの販売なので、他の建て売り数は０で正しい\n",
    "    df = df.fillna({'tateuri_su': 0, 'tochiuri_su':0 , 'joken_su':0 })\n",
    "    \n",
    "    # 同現場での階数ごとの販売数は、gotoデータとつきあわせると正確に出そうだが、とりあえず０で補完する。\n",
    "    df = df.fillna({'hy1f_date_su':0, 'hy2f_date_su':0, 'hy3f_date_su':0})\n",
    "\n",
    "    # 家屋面積(平米) (kaoku_hb)\n",
    "    # 欠損しているところは、家屋有無が(無)なので、0で補完する出正しい。\n",
    "    # 道路面積(mseki_rd_hb), ゴミ、公園等面積(mseki_dp_hb)は大半がゼロなのでゼロで補完しておく\n",
    "    df['kaoku_hb'] = df['kaoku_hb'].fillna(0)\n",
    "    df = df.fillna({'kaoku_hb':0, 'mseki_rd_hb':0, 'mseki_dp_hb':0})\n",
    "    \n",
    "    # 道路\n",
    "    # 扱いが難しい。road1〜road4まであるが、road1だけのものもあれば、road1〜4まで４つあるものまで。\n",
    "    # とりあえず、road1だけを採用し、接する道路数を表す項目を追加することにする。\n",
    "    # Future TODO\n",
    "    # road2〜road4のデータの採用のしかた\n",
    "    \n",
    "    # road1\n",
    "    # road1_hkとroad1_sbをダミー変数化する。\n",
    "    # road2〜road4の有無で、道路数を表すroad_numを作る\n",
    "    # road2～road4の間口(road_mg)でトータルの間口を表すroad_mgを作る\n",
    "    # TODO: road2〜road4を削除\n",
    "    df = pd.merge(df, pd.get_dummies(df[['road1_hk','road1_sb']],drop_first = False), left_index = True, right_index = True)\n",
    "    df['road_num']=df.apply(lambda x: 4 if x['road4_fi']!=0 else 3 if x['road3_fi']!=0 else 2 if x['road2_fi']!=0 else 1, axis=1)\n",
    "    df['road_mg']=df['road2_mg']+df['road3_mg']+df['road4_mg']\n",
    "    df['road_mg']=df['road_mg'].fillna(0)\n",
    "    \n",
    "    #kaoku_umとyheki_umuを0と1で置き換え\n",
    "    df['kaoku_um']=df.apply(lambda x: 0 if x['kaoku_um']==\"（無）\" else 1, axis=1)\n",
    "    df['yheki_umu']=df.apply(lambda x: 0 if x['yheki_umu']==\"（無）\" else 1, axis=1)\n",
    "    \n",
    "    #yheki_yohiを0と1で置き換え\n",
    "    df['yheki_yohi']=df.apply(lambda x: 0 if x['yheki_yohi']==\"（不要）\" else 1, axis=1)\n",
    "    \n",
    "    #kborjsを0と1で置き換え。\"公募\"に変換ミスがあって、３通りあるため、「実測」で値を決める\n",
    "    df['kborjs']=df.apply(lambda x: 0 if x['kborjs']=='実測' else 1, axis=1)\n",
    "    \n",
    "    # 引渡の状態 hw_status\n",
    "    # 善し悪しを表しそうなので数値化したいが、とりあえずはダミー変数化する。\n",
    "    df = pd.merge(df, pd.get_dummies(df[['hw_status']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    #都市計画区域別 toshikuiki1とtoshikuiki２　toshikuiki2があればそちらを採用する。\n",
    "    #一度toshikuiki2がカラの場合にtoshikuiki(新設)に特殊な値を入れて比較しないとうまくいかない。他に方法がありそうだが\n",
    "    df['toshikuiki']=df['toshikuiki2'].fillna('empty')\n",
    "    df['toshikuiki'] = df.apply(lambda x: x['toshikuiki1'] if x['toshikuiki']==\"empty\" else x['toshikuiki2'], axis=1)\n",
    "    df = pd.merge(df, pd.get_dummies(df[['toshikuiki']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # 高度地区(kodochiku) ダミー変数化する\n",
    "    df = pd.merge(df, pd.get_dummies(df[['kodochiku']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # chikukeikaku, keikakuroad, kaihatsukyoka, t53kyoka, hokakyokaを0,1に変換\n",
    "    df['chikukeikaku']=df.apply(lambda x: 0 if x['chikukeikaku']==\"（無）\" else 1, axis=1)\n",
    "    df['keikakuroad']=df.apply(lambda x: 0 if x['keikakuroad']==\"（無）\" else 1, axis=1)\n",
    "    df['kaihatsukyoka']=df.apply(lambda x: 0 if x['kaihatsukyoka']==\"（不要）\" else 1, axis=1)\n",
    "    df['t53kyoka']=df.apply(lambda x: 0 if x['t53kyoka']==\"（不要）\" else 1, axis=1)\n",
    "    df['hokakyoka']=df.apply(lambda x: 0 if x['hokakyoka']==\"（不要）\" else 1, axis=1)\n",
    "    \n",
    "    # 防火地区をダミー変数化\n",
    "    df = pd.merge(df, pd.get_dummies(df[['bokachiiki']],drop_first = False), left_index = True, right_index = True)\n",
    "    \n",
    "    # 最低敷地面積(minmenseki) 欠損がある。ゼロで補完する\n",
    "    df['minmenseki'] = df['minmenseki'].fillna(0)\n",
    "    \n",
    "    # その他規制①～④(hokakisei1～4)\n",
    "    # 四つの列でダミー変数化する必要あり。\n",
    "    \n",
    "    # まず、表記を一意にしておき...\n",
    "    kisei_map = {'公有地拡大推進法':'公拡法', '文化財保護法':'埋蔵文化財', '文化財保護法（埋蔵文化財）':'埋蔵文化財', '景観地区':'景観法','東日本大震災復興特別区域法':'東日本震災復興特', '農地法届出要':'農地法', '43条第1項ただし書き許可':'43条許可'}\n",
    "    df['hokakisei1']=df['hokakisei1'].replace(kisei_map)\n",
    "    df['hokakisei2']=df['hokakisei2'].replace(kisei_map)\n",
    "    df['hokakisei3']=df['hokakisei3'].replace(kisei_map)\n",
    "    df['hokakisei4']=df['hokakisei4'].replace(kisei_map)\n",
    "       \n",
    "    # カラのダミー変数列をつくっておいて...\n",
    "    kisei_dict = {}\n",
    "    for x in hokakisei_cols:\n",
    "        kisei_dict[x] = np.zeros(len(df), dtype=np.int)\n",
    "    \n",
    "    # ダミー変数列を作って...\n",
    "    for i in range(len(df)):\n",
    "        name = df.at[i,'hokakisei1']\n",
    "        if ( type(name) != float):\n",
    "            kisei = kisei_dict[name]\n",
    "            kisei[i]=1\n",
    "        name = df.at[i,'hokakisei2']\n",
    "        if ( type(name) != float):\n",
    "            kisei = kisei_dict[name]\n",
    "            kisei[i]=1\n",
    "        name = df.at[i,'hokakisei3']\n",
    "        if ( type(name) != float):\n",
    "            kisei = kisei_dict[name]\n",
    "            kisei[i]=1\n",
    "        name = df.at[i,'hokakisei4']\n",
    "        if ( type(name) != float):\n",
    "            kisei = kisei_dict[name]\n",
    "            kisei[i]=1\n",
    "    \n",
    "    # 元のDataFrameとダミー変数化したものを連結して..\n",
    "    df = pd.concat([df, pd.DataFrame(kisei_dict)], axis=1)\n",
    "    \n",
    "    # 不要になったhokakisei1～hokakisei4を削除する\n",
    "    df = df.drop(['hokakisei1','hokakisei2','hokakisei3','hokakisei4'], axis=1)\n",
    "    \n",
    "    # kinshijikoを0,1に変換\n",
    "    df['kinshijiko']=df.apply(lambda x: 0 if x['kinshijiko']==\"（無）\" else 1, axis=1)\n",
    "    \n",
    "    # 路線価格(rosenka_hb)\n",
    "    # 公示価格(koji_hb)\n",
    "    # 基準地価(kijun_hb)\n",
    "    # 路線価格と基準地価には欠損(値が0)あり。公示価格は欠損なし。\n",
    "    # 公示価格だけを残す。\n",
    "    # df = df.drop(['rosenka_hb','kijun_hb'],axis=1)\n",
    "\n",
    "    # 有効宅地面積(mseki_yt_hb)\n",
    "    # 道路(mseki_rd_hb)\n",
    "    # ゴミ置場・公園等(mseki_dp_hb)\n",
    "    # 相関不明。そのまま残しておく。\n",
    "    \n",
    "    # 土地最小面積～建物平均面積\n",
    "    # tc_mseki_min_hb～tt_mseki_avg_hb\n",
    "    # 地価に関係ないと思われるので落とす。\n",
    "    # df = df.drop(['tc_mseki_min_hb','tc_mseki_max_hb','tt_mseki_min_hb','tt_mseki_max_hb','tc_mseki_avg_hb','tt_mseki_avg_hb'], axis=1)\n",
    "    \n",
    "    # 幅員4m未満道路の通過(fi4m_yohi)と幅員3m以上4m未満道路の通過距離(fi4m_kyori)\n",
    "    # fi4m_yoshiが否なら、fi4m_kyoriが０。fi3m...の項目も同様。\n",
    "    # よって、fi4m_yohiとfi3m_yohiは削除する。\n",
    "    # かつ、fi4m_kyori, fi3m_kyoriが欠損しているところは、yohiがちゃんと否になっているので、0で埋める。\n",
    "    df = df.drop(['fi4m_yohi','fi3m_yohi'],axis=1)\n",
    "    df['fi4m_kyori']=df['fi4m_kyori'].fillna(0)\n",
    "    df['fi3m_kyori']=df['fi3m_kyori'].fillna(0)\n",
    "    \n",
    "    # バス要否、バス本数\n",
    "    # 後続の交通手段のところで、バスを使うことになっていないにもかかわらず、要否が要になっているデータがあり\n",
    "    # 信ぴょう性に欠けるので、削除する。\n",
    "    df = df.drop(['bus_yohi','bus_hon'], axis=1)\n",
    "    \n",
    "    # コンビニ有無(sho_conv)～騒音有無(shu_soon)\n",
    "    # ２値データ。ありは「〇」。これを0/1に変換する。\n",
    "    df['sho_conv'] = df['sho_conv'].map({'○':1, np.NaN:0})\n",
    "    df['sho_super'] = df['sho_super'].map({'○':1, np.NaN:0})\n",
    "    df['sho_shoten'] = df['sho_shoten'].map({'○':1, np.NaN:0})    \n",
    "    df['sho_market'] = df['sho_market'].map({'○':1, np.NaN:0})\n",
    "    df['shu_jutaku'] = df['shu_jutaku'].map({'○':1, np.NaN:0})\n",
    "    df['shu_park'] = df['shu_park'].map({'○':1, np.NaN:0})\n",
    "    df['shu_shop'] = df['shu_shop'].map({'○':1, np.NaN:0})\n",
    "    df['shu_factory'] = df['shu_factory'].map({'○':1, np.NaN:0})\n",
    "    df['shu_hvline'] = df['shu_hvline'].map({'○':1, np.NaN:0})\n",
    "    df['shu_tower'] = df['shu_tower'].map({'○':1, np.NaN:0})\n",
    "    df['shu_bochi'] = df['shu_bochi'].map({'○':1, np.NaN:0})\n",
    "    df['shu_sogi'] = df['shu_sogi'].map({'○':1, np.NaN:0})\n",
    "    df['shu_zoki'] = df['shu_zoki'].map({'○':1, np.NaN:0})\n",
    "    df['shu_kokyo'] = df['shu_kokyo'].map({'○':1, np.NaN:0})\n",
    "    df['shu_highway'] = df['shu_highway'].map({'○':1, np.NaN:0})\n",
    "    df['shu_kaido'] = df['shu_kaido'].map({'○':1, np.NaN:0})\n",
    "    df['shu_line_ari'] = df['shu_line_ari'].map({'○':1, np.NaN:0})\n",
    "    df['shu_line_nashi'] = df['shu_line_nashi'].map({'○':1, np.NaN:0})\n",
    "    df['shu_soon'] = df['shu_soon'].map({'○':1, np.NaN:0})\n",
    "    \n",
    "    # 幼稚園徒歩/小学校徒歩/中学校徒歩(gk_yoc_tm/gk_sho_tm/gk_chu_tm)\n",
    "    # 欠損もなく異常値もないため、そのままにする。\n",
    "    \n",
    "    # 隣接物件東戸建（2F以下）～隣接物件北田畑\n",
    "    # ２値データ。ありは「〇」。これを0/1に変換する\n",
    "    df['rs_e_kdate2'] = df['rs_e_kdate2'].map({'○':1, np.NaN:0})\n",
    "    df['rs_e_kdate3'] = df['rs_e_kdate3'].map({'○':1, np.NaN:0})\n",
    "    df['rs_e_parking'] = df['rs_e_parking'].map({'○':1, np.NaN:0})\n",
    "    df['rs_e_zoki'] = df['rs_e_zoki'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_e_m_ari'] = df['rs_e_m_ari'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_e_m_nashi'] = df['rs_e_m_nashi'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_e_tahata'] = df['rs_e_tahata'].map({'○':1, np.NaN:0}) \n",
    "\n",
    "    df['rs_w_kdate2'] = df['rs_w_kdate2'].map({'○':1, np.NaN:0})\n",
    "    df['rs_w_kdate3'] = df['rs_w_kdate3'].map({'○':1, np.NaN:0})\n",
    "    df['rs_w_parking'] = df['rs_w_parking'].map({'○':1, np.NaN:0})\n",
    "    df['rs_w_zoki'] = df['rs_w_zoki'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_w_m_ari'] = df['rs_w_m_ari'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_w_m_nashi'] = df['rs_w_m_nashi'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_w_tahata'] = df['rs_w_tahata'].map({'○':1, np.NaN:0}) \n",
    "    \n",
    "    df['rs_s_kdate2'] = df['rs_s_kdate2'].map({'○':1, np.NaN:0})\n",
    "    df['rs_s_kdate3'] = df['rs_s_kdate3'].map({'○':1, np.NaN:0})\n",
    "    df['rs_s_parking'] = df['rs_s_parking'].map({'○':1, np.NaN:0})\n",
    "    df['rs_s_zoki'] = df['rs_s_zoki'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_s_m_ari'] = df['rs_s_m_ari'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_s_m_nashi'] = df['rs_s_m_nashi'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_s_tahata'] = df['rs_s_tahata'].map({'○':1, np.NaN:0}) \n",
    "    \n",
    "    df['rs_n_kdate2'] = df['rs_n_kdate2'].map({'○':1, np.NaN:0})\n",
    "    df['rs_n_kdate3'] = df['rs_n_kdate3'].map({'○':1, np.NaN:0})\n",
    "    df['rs_n_parking'] = df['rs_n_parking'].map({'○':1, np.NaN:0})\n",
    "    df['rs_n_zoki'] = df['rs_n_zoki'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_n_m_ari'] = df['rs_n_m_ari'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_n_m_nashi'] = df['rs_n_m_nashi'].map({'○':1, np.NaN:0}) \n",
    "    df['rs_n_tahata'] = df['rs_n_tahata'].map({'○':1, np.NaN:0}) \n",
    "\n",
    "    # 路線(rosen_nm1/rosen_nm2)、駅(eki_nm1/eki_nm2)\n",
    "    # 残してある公示価格に反映されていると考えて、ここでは削除する\n",
    "    df[['bus', 'walk']] = df.apply(calculateLogistics, axis=1)\n",
    "    df=df.drop(['rosen_nm1','eki_nm1','bas_toho1','eki_kyori1','bastei_nm1','teiho1','rosen_nm2','eki_nm2','bas_toho2','eki_kyori2','bastei_nm2','teiho2'],axis=1)\n",
    "\n",
    "    # 最後に不要になった列を削除する\n",
    "    # road_hkは、gotoデータと結合した後に補完に使うので、ここでは削除しないでおく。\n",
    "    df=df.drop(['yoto1','kempei1','yoto2','kempei2','yoseki2','road1_sb','toshikuiki1','yoto'],axis=1)\n",
    "    df=df.drop(['usui','road2_hk','road2_sb','road2_fi','road2_mg','road3_hk','road3_sb','road3_fi','road3_mg','road4_hk','road4_sb','road4_fi','road4_mg'],axis=1)\n",
    "    df=df.drop(['hw_status','toshikuiki','toshikuiki2','toshikuiki','kodochiku','bokachiiki'],axis=1)\n",
    "    df=df.drop(['gas', 'gk_sho_kyori', 'gk_chu_kyori'],axis=1)\n",
    "    \n",
    "    # testデータの項目gc_yoc_tmに欠損あり。\n",
    "    # 平均値で欠損補完する\n",
    "    df['gk_yoc_tm'] = df['gk_yoc_tm'].fillna(df['gk_yoc_tm'].mean())\n",
    "        \n",
    "    return df\n",
    "\n",
    "def select_yoto(x):\n",
    "    # yoto2はNaNを含む\n",
    "    # 値がない場合、typeはfloatで、データがある場合にはstrになる様子。\n",
    "    # そこで、型がstrかどうかで、値の有無を判定する。\n",
    "    if ( type(x['yoto2']) == str ):\n",
    "        yoto =x['yoto2']\n",
    "        kempei = x['kempei2']\n",
    "        yoseki =x['yoseki2']\n",
    "    else:\n",
    "        yoto =x['yoto1']\n",
    "        kempei =x['kempei1']\n",
    "        yoseki =x['yoseki1'] \n",
    "    return pd.Series([yoto, kempei, yoseki])\n",
    "\n",
    "# 駅から徒歩、バス等の交通手段を、バスと徒歩の二つの利用時間に変換する\n",
    "# バスを使わない場合には、busを0にすることで対応。\n",
    "\n",
    "def calculateLogistics(x):\n",
    "    if ( x['bas_toho1'] == 'バス' ):\n",
    "        bus = x['eki_kyori1']\n",
    "        walk = x['teiho1']\n",
    "    else:\n",
    "        bus = 0\n",
    "        walk = x['eki_kyori1']\n",
    "    \n",
    "    return pd.Series([bus, walk])\n",
    "\n",
    "# 法規制の処理用関数\n",
    "def put_name(col, name):\n",
    "    if ( type(name) != float ):\n",
    "        col.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_goto(goto, kobetsu_cols):\n",
    "    # コピーしてから加工する\n",
    "    df = goto.copy()\n",
    "    \n",
    "    # 削除対象のカラム名を追加していくリスト\n",
    "    del_list = []\n",
    "    \n",
    "    # 階数・プラン(levelplan)\n",
    "    # 求めるものは土地の販売価格なので不要とする。\n",
    "    del_list.append(\"levelplan\")\n",
    "    \n",
    "    # 幅員(fukuin)\n",
    "    # 欠損および０の場合には、genbaデータと結合したroad1_fiの値をコピーする\n",
    "    df['fukuin'] = df['fukuin'].fillna(0)\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'fukuin'] ==0 ) :\n",
    "            df.at[i,'fukuin'] = df.at[i,'road1_fi']\n",
    "    \n",
    "    # 道路状況(road_st)\n",
    "    # 以下のように値にマップする。欠損は\"問題なし”にマップすることにする。\n",
    "    df['road_st'] = df['road_st'].fillna(\"問題なし\")\n",
    "    df['road_st'] = df['road_st'].map({'未舗装':0, '問題なし':1, '歩道あり':1, '歩道+緑地帯あり':2})\n",
    "    \n",
    "    # 間口(magutchi)\n",
    "    # 幅員と同じように補完する。\n",
    "    df['magutchi'] = df['magutchi'].fillna(0)\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'magutchi'] ==0 ) :\n",
    "            df.at[i,'magutchi'] = df.at[i,'road1_mg']    \n",
    "    \n",
    "    # 接道方位\t(setsudo_hi)\n",
    "    # 幅員と同じように補完してから、ダミー変数化する。\n",
    "    df['setsudo_hi' ] = df['setsudo_hi'].fillna('unknown')\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'setsudo_hi']=='unknown'):\n",
    "            df.at[i,'setsudo_hi']=df.at[i,'road1_hk']\n",
    "\n",
    "    # ダミー変数化。\n",
    "    # 単にダミー変数化したあと、複数方向が一つに組み合わさっている場合があるので、分解する\n",
    "    df['setsudo_hi']=df['setsudo_hi'].replace({'北+東':'北＋東', '北+西':'北＋西', '北西+南西':'北西＋南西','南東+南西':'南東＋南西'})\n",
    "    df = pd.merge(df, pd.get_dummies(df[['setsudo_hi']],drop_first = False), left_index = True, right_index = True)\n",
    "    # 全行処理する\n",
    "    for i in range(len(df)):\n",
    "        process_setsudo_hi(df,i)\n",
    "\n",
    "    # 複数方向が組み合わさった列を削除する\n",
    "    del_list.extend(['setsudo_hi_北東＋北西','setsudo_hi_北東＋南東','setsudo_hi_北東＋南西','setsudo_hi_北西＋北東'])\n",
    "    del_list.extend(['setsudo_hi_北西＋南東','setsudo_hi_北西＋南西','setsudo_hi_北西＋東'])\n",
    "    del_list.extend(['setsudo_hi_北＋北東','setsudo_hi_北＋北西','setsudo_hi_北＋南','setsudo_hi_北＋南東','setsudo_hi_北＋南西','setsudo_hi_北＋東','setsudo_hi_北＋西'])\n",
    "    del_list.extend(['setsudo_hi_南東＋北','setsudo_hi_南東＋北東','setsudo_hi_南東＋北西','setsudo_hi_南東＋南西','setsudo_hi_南東＋北西'])\n",
    "    del_list.extend(['setsudo_hi_南東＋南西','setsudo_hi_南東＋東','setsudo_hi_南東＋西'])\n",
    "    del_list.extend(['setsudo_hi_南西＋北','setsudo_hi_南西＋北東','setsudo_hi_南西＋北西','setsudo_hi_南西＋南東','setsudo_hi_南西＋北','setsudo_hi_南西＋東','setsudo_hi_南西＋西'])\n",
    "    del_list.extend(['setsudo_hi_南＋北','setsudo_hi_南＋北東','setsudo_hi_南＋北西','setsudo_hi_南＋南東','setsudo_hi_南＋南西','setsudo_hi_南＋東','setsudo_hi_南＋西'])\n",
    "    del_list.extend(['setsudo_hi_東＋北','setsudo_hi_東＋南','setsudo_hi_東＋南東','setsudo_hi_東＋南西','setsudo_hi_東＋西'])\n",
    "    del_list.extend(['setsudo_hi_西＋北','setsudo_hi_西＋北東','setsudo_hi_西＋北西','setsudo_hi_西＋東','setsudo_hi_西＋南東','setsudo_hi_西＋南西','setsudo_hi_西＋東'])\n",
    "    del_list.extend(['setsudo_hi_北東＋南','setsudo_hi_北東＋西','setsudo_hi_北西＋南西＋北東','setsudo_hi_南西＋南','setsudo_hi_西＋南'])\n",
    "    del_list.append('setsudo_hi')\n",
    "    del_list.append('road1_hk')\n",
    "    \n",
    "    # 接道形状(setsudo_kj)\n",
    "    # trainデータでは、'良い'が一番多いので、それで補完し、ダミー変数化する。\n",
    "    df['setsudo_kj' ] = df['setsudo_kj'].fillna('良い')\n",
    "    df = pd.merge(df, pd.get_dummies(df[['setsudo_kj']],drop_first = False), left_index = True, right_index = True)\n",
    "    del_list.append('setsudo_kj')\n",
    "    \n",
    "    # 地型(jigata)\n",
    "    # trainデータで一番多い'整形地’で補完し、ダミー変数化する。\n",
    "    df['jigata'] = df['jigata'].fillna('整形地')\n",
    "    df = pd.merge(df, pd.get_dummies(df[['jigata']],drop_first = False), left_index = True, right_index = True)\n",
    "    del_list.append('jigata')\n",
    "    \n",
    "    # 日当たり(hiatari)\n",
    "    # trainデータで多い'普通'で補完し、ダミー変数化する\n",
    "    # genbaデータから補完できるかもしれない。\n",
    "    df['hiatari'] = df['hiatari'].fillna('普通')\n",
    "    df = pd.merge(df, pd.get_dummies(df[['hiatari']],drop_first = False), left_index = True, right_index = True)\n",
    "    del_list.append('hiatari')\n",
    "    \n",
    "    # 個別要因①〜④\n",
    "    # ダミー変数化する  \n",
    "    kobetsu_map = {'信号近い':'信号前'}\n",
    "    df['kobetsu1']=df['kobetsu1'].replace(kobetsu_map)\n",
    "    df['kobetsu2']=df['kobetsu2'].replace(kobetsu_map)\n",
    "    df['kobetsu3']=df['kobetsu3'].replace(kobetsu_map)\n",
    "    df['kobetsu4']=df['kobetsu4'].replace(kobetsu_map)\n",
    "\n",
    "    # ステップ２：\n",
    "    kobetsu_dict = {}\n",
    "    for x in kobetsu_cols:\n",
    "        kobetsu_dict[x] = np.zeros(len(df), dtype=np.int)\n",
    "\n",
    "    # ステップ３：\n",
    "    for i in range(len(df)):\n",
    "        name = df.at[i,'kobetsu1']\n",
    "        if ( type(name) != float):\n",
    "            kobetsu= kobetsu_dict[name]\n",
    "            kobetsu[i]=1\n",
    "        name = df.at[i,'kobetsu2']\n",
    "        if ( type(name) != float):\n",
    "            kobetsu= kobetsu_dict[name]\n",
    "            kobetsu[i]=1\n",
    "        name = df.at[i,'kobetsu3']\n",
    "        if ( type(name) != float):\n",
    "            kobetsu= kobetsu_dict[name]\n",
    "            kobetsu[i]=1\n",
    "        name = df.at[i,'kobetsu4']\n",
    "        if ( type(name) != float):\n",
    "            kobetsu= kobetsu_dict[name]\n",
    "            kobetsu[i]=1\n",
    "\n",
    "    # 元のDataFrameとダミー変数化したものを連結\n",
    "    df = pd.concat([df, pd.DataFrame(kobetsu_dict)], axis=1)\n",
    "    \n",
    "    # 不要になった列を削除する\n",
    "    del_list.append('kobetsu1')\n",
    "    del_list.append('kobetsu2')\n",
    "    del_list.append('kobetsu3')\n",
    "    del_list.append('kobetsu4')\n",
    "    \n",
    "    df = df.drop(del_list, axis=1)\n",
    "    \n",
    "    # V5で追加するtt_msekiの補完処理。ここから。\n",
    "    # 1. tt_mseki_avg_hb, tt_mseki_max_hb で補完\n",
    "    df['tt_mseki_avg_hb'] = df['tt_mseki_avg_hb'].fillna(0)\n",
    "    df['tt_mseki_max_hb'] = df['tt_mseki_max_hb'] .fillna(0)\n",
    "    df['tt_mseki'] = df.apply(lambda x : x['tt_mseki'] if x['tt_mseki'] != 0 else x['tt_mseki_avg_hb'] if x['tt_mseki_avg_hb']!= 0 else x['tt_mseki_max_hb']  if x['tt_mseki_max_hb'] != 0 else 0, axis=1)\n",
    "\n",
    "    # 1. tt_msekiがゼロ以外の集合に対して、容積率ごとに建物面積との比率を求める\n",
    "    # 1-1 tt_mseki != 0の集合を作る\n",
    "    # 1-2 容積率yoseki1でgroupbyする\n",
    "    # 1-3 一つの容積率についてのDataFrameを取得\n",
    "    # 1-4 当該DataFrameでtt_msekiとtc_msekiのそれぞれの合計値を求め、tt_mseki/tc_msekiの比ratioをともめる\n",
    "    # 1-5 容積率とratioの組をdictに登録する\n",
    "    df2 = df[df['tt_mseki']!=0]\n",
    "    yoseki_gr = df2.groupby('yoseki1')\n",
    "    ratio_dict = {}\n",
    "    for y in yoseki_gr.groups.keys():\n",
    "        # 1-3\n",
    "        d = yoseki_gr.get_group(y)\n",
    "        #1-4\n",
    "        total_tc = d['tc_mseki'].sum()\n",
    "        total_tt = d['tt_mseki'].sum()\n",
    "        ratio = total_tt/total_tc\n",
    "        #1-5\n",
    "        ratio_dict[y]= ratio\n",
    "    \n",
    "    df['tt_mseki'] = df.apply(calc_tt_mseki, rdict = ratio_dict, axis=1)\n",
    "    \n",
    "    # V4では削除していた列。V5では一旦削除せず、`feature_importances_`を確認することにする\n",
    "    # 土地最小面積～建物平均面積\n",
    "    # tc_mseki_min_hb～tt_mseki_avg_hb\n",
    "    # 地価に関係ないと思われるので落とす。\n",
    "    # df = df.drop(['tc_mseki_min_hb','tc_mseki_max_hb','tt_mseki_min_hb','tt_mseki_max_hb','tc_mseki_avg_hb','tt_mseki_avg_hb'], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def calc_tt_mseki( x , rdict ):\n",
    "    if x['tt_mseki'] != 0:\n",
    "        return x['tt_mseki']\n",
    "    yoseki = x['yoseki1']\n",
    "    ratio = rdict[yoseki]\n",
    "    tt_mseki = x['tc_mseki'] * ratio\n",
    "    return tt_mseki\n",
    "\n",
    "def process_setsudo_hi(df,i):\n",
    "    if df.at[i,'setsudo_hi_北東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋南']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋西']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋南西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋南']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋北']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋西']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋南']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 現場データのtrainとtestを連結\n",
    "train = pd.read_csv(\"data/train_genba.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"data/test_genba.tsv\", sep='\\t')\n",
    "\n",
    "# 2. 連結した現場データの欠損補完やhokakisei1～4のダミー変数化を行う\n",
    "genba = pd.concat([train,test],axis=0, ignore_index=True)\n",
    "hokakisei_list = create_list( genba, {'hokakisei1','hokakisei2','hokakisei3','hokakisei4'})\n",
    "processed_genba = preprocess_genba(genba, hokakisei_list)\n",
    "\n",
    "# 3. 号棟データのtrainを読みこみ、目的変数を分離しておく。\n",
    "train = pd.read_csv(\"data/train_goto.tsv\",sep='\\t')\n",
    "train_target = pd.DataFrame(train[['id','keiyaku_pr']])\n",
    "train = train.drop(['keiyaku_pr'],axis=1)\n",
    "\n",
    "# 4. 号棟データのtestを読み込み、上記のtrain号棟データと連結\n",
    "test = pd.read_csv(\"data/test_goto.tsv\",sep='\\t')\n",
    "goto = pd.concat([train,test])\n",
    "\n",
    "# 5. 連結済みの現場データと連結済み号棟データをジョイン\n",
    "joined_goto = goto.merge(processed_genba, how='left', on='pj_no' )\n",
    "\n",
    "# 6. ジョイン済号棟データの欠損補完やkobetsu1～4のダミー変数化を行う\n",
    "kobetsu_list = create_list( joined_goto,  ['kobetsu1','kobetsu2','kobetsu3','kobetsu4'])\n",
    "processed_goto = preprocess_goto(joined_goto, kobetsu_list)\n",
    "\n",
    "# 7. 号棟データのtrainとtestを分離\n",
    "train_goto = processed_goto[processed_goto['id'].str.contains('train_')]\n",
    "test_goto = processed_goto[processed_goto['id'].str.contains('test_')]\n",
    "\n",
    "# 8. 号棟データのtrainから分離した真の目的変数から、学習で使用する単価面積を算出\n",
    "# train_target['tanka_pr']=train_target['keiyaku_pr']/train_target['tc_mseki']\n",
    "\n",
    "# 9. 処理結果をファイル出力\n",
    "# processed_train_goto_x.csv ... 教師データ　説明変数\n",
    "# processed_train_goto_y.csv ... 教師データ　目的変数\n",
    "# processed_test_goto_x.csv ... 予測用データ\n",
    "train_goto.to_csv('data/processed_train_goto_x_v7.csv', index=False)\n",
    "test_goto.to_csv('data/processed_test_goto_x_v7.csv', index=False)\n",
    "train_target.to_csv('data/processed_train_goto_y_v7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
