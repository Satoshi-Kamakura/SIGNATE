{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProcessDataForSubmittingTrainV7XGBでの判明事項\n",
    "訓練データの20%の1293件のデータで検証した結果\n",
    "-　平均値を超えている件数が436件あり、平均以上に引っ張られている形\n",
    "- 800%, 400%外れているケースあり。これは同じ現場でも他の号棟と異なるために安くなっているケースがあった\n",
    "- また、他の号棟に比べて面積(tc_mseki)が広いが、価格に反映できていないケースがある\n",
    "\n",
    "⇒学習データに入っていないために、予測に反映できていないように見える。\n",
    "\n",
    "　⇒学習と検証データに分けるパターンを複数作成し、平均もしくは中間の値から価格を決めるのはどうか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はずれ値に関して調査する\n",
    "1. 教師データから外れ値（⇒極端に安い物件）をピックアップする\n",
    "1. 教師データに対して、その教師データで学習したモデルで予測し、その外れ値にどのような予測ができているか確認する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### みつかった外れ値物件\n",
    "- pj_no = 2019   280万と2800万\n",
    "- pj_no = 2192   300万と3000万\n",
    "- pj_no = 758     350万と2800万\n",
    "- pj_no = 2504   360万と3700万\n",
    "- pj_no = 2412   550万と2500万\n",
    "- pj_no = 2036  1000万と1700万"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## わかったこと\n",
    "- pj_no 2019 : niwasakiが同じpj_noのものに比べて半分 他：4.2  安いもの:2.7\n",
    "- pj_no 2192 : setsudo_hiが他の物件と違う　　他：東　安い：南\n",
    "- pj_no 758 : 他の物件より悪条件が多い　tc_msekiが極端にちいさい maguchi, niwasakiが極端にちいさい\n",
    "- pj_no 2504 : 差異無し　判定無理\n",
    "- pj_no 2412 : 安い物件もちゃんと判定できている9%の誤差。単に学習データに含まれているからかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## やってみたいこと\n",
    "- pj_no 758より ... tc_msekiとtc_mseki_avgとの比のカラムを追加する\n",
    "- pj_no 758より ... mabuchiが狭いもの物件に対して、間口狭のカテゴリを１にする\n",
    "- pj_no 1535より ... 当該pj_noで最も狭い物件にフラグを立てる\n",
    "- pj_no 1047より ... 最大の面積を持つ2502がおかしい。tc_msekiの反映に失敗している様子。やはり単価で予測すべきか\n",
    "- pj_no 408より ... levelplanをdropしているのがまずいと思われる。次はこれをやるべき。補完が難しいかもしれない。\n",
    "- pj_no 1457より ... levelplanが土地売りのものを反映できていない。やはりdropしているのがまずい"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ローカル向け処理\n",
    "- X_train, X_evalは、idとpj_no列をdropしてから、訓練、評価に使う\n",
    "- Y_train, Y_evalは、tanka_pr列を利用する\n",
    "#### 教師データ：訓練用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning...\n",
      "20.882111721\n",
      "start estimating...\n",
      "[ 3.65103007]\n"
     ]
    }
   ],
   "source": [
    "# 共通処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v7.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v7.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_eval.to_csv(\"data/X_eval.csv\", index=False)\n",
    "Y_train.to_csv(\"data/Y_train.csv\", index=False)\n",
    "Y_eval.to_csv(\"data/Y_eval.csv\", index=False)\n",
    "\n",
    "train_x = pd.read_csv('data/X_train.csv').drop(['id','pj_no'],axis=1)\n",
    "train_y = pd.read_csv('data/Y_train.csv').drop(['id'],axis=1)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "print(f\"start learning...\")\n",
    "xgboost_opt = XGBRegressor(**params, seed=42, n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "xgboost_opt.fit(train_x, train_y)\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/processed_train_goto_x_v7.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/processed_train_goto_y_v7.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/processed_train_goto_y_v7.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/processed_train_goto_x_v7.csv\"),on='id')\n",
    "output.to_csv(\"data/train_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start estimating...\n",
      "[ 8.81650293]\n"
     ]
    }
   ],
   "source": [
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/Y_eval.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/X_eval.csv\"),on='id')\n",
    "output.to_csv(\"data/eval_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_x = pd.read_csv('data/X_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_x['pred_keiyaku_pr']=pd.Series(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df =pd.merge(eval_x, pd.read_csv('data/Y_eval.csv'), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['diff']=(abs(df['pred_keiyaku_pr']-df['keiyaku_pr'])/df['keiyaku_pr'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/difference.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimatorsが700のケースでsubmitしてみることにする(7/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")\n",
    "test_pred = xgboost_opt.predict(test_x.drop(['id','pj_no'],axis=1))\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(test_pred).astype(np.int64)\n",
    "submit.to_csv('data/submit4.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここからSageMaker用のデータを作る処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv')\n",
    "train_y = pd.read_csv('data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.concat([train_y.drop(['id','keiyaku_pr','tc_mseki'],axis=1),train_x.drop(['id','pj_no'],axis=1)],axis=1)\n",
    "train_input.to_csv('data/sagemaker_input.csv', header=None, index=False)\n",
    "eval_x = pd.read_csv('data/X_eval.csv')\n",
    "eval_x.drop(['id','pj_no'],axis=1).to_csv('data/sagemaker_eval_input.csv',header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMakerの出力から精度を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2_y = pd.read_csv('data/sagemaker_eval_input.csv.out', header=None)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( mean_absolute_percentage_error(ans_y.values,pred2_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMaker用予測データを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = test_x.drop(['id','pj_no'],axis=1)\n",
    "test_input.to_csv('data/sagemaker_test_input.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker出力からsubmit用データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tanka = pd.read_csv(\"data/sagemaker_test_input.csv.out\", header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id', 'tc_mseki']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['tanka_pr']=tanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['price']=(submit['tc_mseki']*submit['tanka_pr']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.loc[:,['id','price']].to_csv('data/submit3.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
