{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理したデータをSageMaker用とローカル用とに作り分ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 出力データ仕様\n",
    "#### 教師データ：訓練用\n",
    "- 目的変数　Y_train.csv　　index, columnあり\n",
    "- 説明変数　X_train.csv　　index, columnあり\n",
    "\n",
    "#### 教師データ：検証用\n",
    "- 目的変数　Y_eval.csv　index, columnあり\n",
    "- 説明変数　X_eval.csv　index, columnあり\n",
    "\n",
    "#### 教師データ：メタデータ  ⇒必要と思ったが、X_eval, Y_evalに含まれるので無しにする\n",
    "- train_meta.csv  id, pj_no, 面積を保持\n",
    "- eval_meta.csv  同上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 SageMaker向けでの処理\n",
    "- データはS3ではなく、ノートブックから直接read_csvできるところに配置する\n",
    "- indexやcolumnはSageMaker上でread_csvするときに必要に応じて無視する\n",
    "- 無視するためには、indexやcolumnsなしでS3へ出力すること\n",
    "- 訓練するときには、入力となる教師データの一列目は目的変数にする必要があるが、SageMaker上のロジックでこのデータを組み立てること"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ローカル向け処理\n",
    "- X_train, X_evalは、idとpj_no列をdropしてから、訓練、評価に使う\n",
    "- Y_train, Y_evalは、tanka_pr列を利用する\n",
    "#### 教師データ：訓練用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 共通処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v7.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v7.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#　データを分割して出力する\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_eval.to_csv(\"data/X_eval.csv\", index=False)\n",
    "Y_train.to_csv(\"data/Y_train.csv\", index=False)\n",
    "Y_eval.to_csv(\"data/Y_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ローカル向け処理。読み込んで学習、検証データと比較してスコアを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv').drop(['id','pj_no'],axis=1)\n",
    "train_y = pd.read_csv('data/Y_train.csv').drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keiyaku_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   keiyaku_pr\n",
       "0    24500000\n",
       "1    24800000\n",
       "2    27800000\n",
       "3    18900000\n",
       "4    37000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.91361586100004\n",
      "[ 9.83545336]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=400, max_depth=200, min_samples_split=2,n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "model.fit(train_x.values, train_y.values.ravel() )\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id'],axis=1)\n",
    "pred_y = model.predict(eval_x.values)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoostを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.315703328999916\n"
     ]
    }
   ],
   "source": [
    "xgboost_opt = XGBRegressor(**params, seed=42, n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "xgboost_opt.fit(train_x, train_y)\n",
    "end = time.perf_counter()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.81650293]\n"
     ]
    }
   ],
   "source": [
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここからSageMaker用のデータを作る処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv')\n",
    "train_y = pd.read_csv('data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.concat([train_y.drop(['id','keiyaku_pr','tc_mseki'],axis=1),train_x.drop(['id','pj_no'],axis=1)],axis=1)\n",
    "train_input.to_csv('data/sagemaker_input.csv', header=None, index=False)\n",
    "eval_x = pd.read_csv('data/X_eval.csv')\n",
    "eval_x.drop(['id','pj_no'],axis=1).to_csv('data/sagemaker_eval_input.csv',header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMakerの出力から精度を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2_y = pd.read_csv('data/sagemaker_eval_input.csv.out', header=None)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( mean_absolute_percentage_error(ans_y.values,pred2_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMaker用予測データを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = test_x.drop(['id','pj_no'],axis=1)\n",
    "test_input.to_csv('data/sagemaker_test_input.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker出力からsubmit用データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tanka = pd.read_csv(\"data/sagemaker_test_input.csv.out\", header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id', 'tc_mseki']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['tanka_pr']=tanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['price']=(submit['tc_mseki']*submit['tanka_pr']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.loc[:,['id','price']].to_csv('data/submit3.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
