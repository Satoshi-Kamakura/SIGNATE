{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここはいろいろ実験的なコードを書くところとする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7/9 levelplan補完コード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data/test_goto.tsv\", sep='\\t')\n",
    "df['levelplan'] = df.apply(lambda x : '土地売り' if type(x['levelplan']) == float and x['tt_mseki']==0 else x['levelplan'], axis=1)\n",
    "df.to_csv(\"data/tmp.csv\")\n",
    "df['levelplan']=df['levelplan'].fillna('2F/4LDK')\n",
    "df['levelplan'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['levelplan']=df['levelplan'].fillna('2F/4LDK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['levelplan'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7/7 実験用コード\n",
    "setsudo_hi列の改善\n",
    "'南＋北西'といった複数の組み合わせを、'南'と'北西'の二つに分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データを呼んでカラムを抽出し、横に並んだカラムを縦に並べてファイル出力したい\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/processed_train_goto_x.csv\")\n",
    "cols = pd.DataFrame(df.columns.values)\n",
    "cols.to_csv('data/columns.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setsudo_hiを処理するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/train_goto.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '+'と'＋'が混ざっているので統一する\n",
    "df['setsudo_hi']=df['setsudo_hi'].replace({'北+東':'北＋東', '北+西':'北＋西', '北西+南西':'北西＋南西','南東+南西':'南東＋南西'})\n",
    "df = pd.merge(df, pd.get_dummies(df[['setsudo_hi']],drop_first = False), left_index = True, right_index = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_setsudo_hi_2(df,i):\n",
    "    if df.at[i,'setsudo_hi_北東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋東']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_北＋西']==1:\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南東＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南西＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋東']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_南＋西']==1:\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋北']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_東＋西']==1:\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋北西']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_北西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋南東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_南東']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋南西']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_南西']=1\n",
    "    elif df.at[i,'setsudo_hi_西＋東']==1:\n",
    "        df.at[i,'setsudo_hi_西']=1\n",
    "        df.at[i,'setsudo_hi_東']=1\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    process_setsudo_hi_2(df,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 地道に'＋'を分解する\n",
    "    def process_setsudo_hi(df):\n",
    "        if df['setsudo_hi_北東＋北西']==1:\n",
    "            df['setsudo_hi_北東']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_北東＋南東']==1:\n",
    "            df['setsudo_hi_北東']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_北東＋南西']==1:\n",
    "            df['setsudo_hi_北東']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_北西＋北東']==1:\n",
    "            df['setsudo_hi_北西']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_北西＋南東']==1:\n",
    "            df['setsudo_hi_北西']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_北西＋南西']==1:\n",
    "            df['setsudo_hi_北西']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_北西＋東']==1:\n",
    "            df['setsudo_hi_北西']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_北＋北東']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_北＋北西']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_北＋南']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_南']=1\n",
    "        elif df['setsudo_hi_北＋南東']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_北＋南西']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_北＋東']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_北＋西']==1:\n",
    "            df['setsudo_hi_北']=1\n",
    "            df['setsudo_hi_西']=1\n",
    "        elif df['setsudo_hi_南東＋北']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_南東＋北東']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_南東＋北西']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_南東＋南西']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_南東＋北西']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_南東＋南西']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_南東＋東']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_南東＋西']==1:\n",
    "            df['setsudo_hi_南東']=1\n",
    "            df['setsudo_hi_西']=1\n",
    "        elif df['setsudo_hi_南西＋北']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_南西＋北']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_南西＋北東']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_南西＋北西']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_南西＋南東']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_南西＋北']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_南西＋東']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_南西＋西']==1:\n",
    "            df['setsudo_hi_南西']=1\n",
    "            df['setsudo_hi_西']=1\n",
    "        elif df['setsudo_hi_南＋北']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_南＋北東']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_南＋北西']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_南＋南東']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_南＋南西']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_南＋東']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_南＋西']==1:\n",
    "            df['setsudo_hi_南']=1\n",
    "            df['setsudo_hi_西']=1\n",
    "        elif df['setsudo_hi_東＋北']==1:\n",
    "            df['setsudo_hi_東']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_東＋南']==1:\n",
    "            df['setsudo_hi_東']=1\n",
    "            df['setsudo_hi_南']=1\n",
    "        elif df['setsudo_hi_東＋南東']==1:\n",
    "            df['setsudo_hi_東']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_東＋南西']==1:\n",
    "            df['setsudo_hi_東']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_東＋西']==1:\n",
    "            df['setsudo_hi_東']=1\n",
    "            df['setsudo_hi_西']=1\n",
    "        elif df['setsudo_hi_西＋北']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_北']=1\n",
    "        elif df['setsudo_hi_西＋北東']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_北東']=1\n",
    "        elif df['setsudo_hi_西＋北西']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_北西']=1\n",
    "        elif df['setsudo_hi_西＋東']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        elif df['setsudo_hi_西＋南東']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_南東']=1\n",
    "        elif df['setsudo_hi_西＋南西']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_南西']=1\n",
    "        elif df['setsudo_hi_西＋東']==1:\n",
    "            df['setsudo_hi_西']=1\n",
    "            df['setsudo_hi_東']=1\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[10,'setsudo_hi_北東＋北西']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('setsudo_hi_北東＋北西', 'occurred at index id')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4b5a4a7202c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_setsudo_hi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4262\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4357\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4358\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4359\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-8cdb785c1afe>\u001b[0m in \u001b[0;36mprocess_setsudo_hi\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 地道に'＋'を分解する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_setsudo_hi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'setsudo_hi_北東＋北西'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'setsudo_hi_北東'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'setsudo_hi_北西'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2477\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('setsudo_hi_北東＋北西', 'occurred at index id')"
     ]
    }
   ],
   "source": [
    "df.apply(process_setsudo_hi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検証用のコードを書く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6/30 V5向けのトライアル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tt_msekiが第３位だが、欠損がtrain/test双方とも0.5%程度ある。⇒容積率ごとの平均のtc_msekiとtt_msekiの比から欠損を補完したい\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "genba = pd.read_csv(\"data/train_genba.tsv\", sep='\\t')\n",
    "goto = pd.read_csv(\"data/train_goto.tsv\",sep='\\t')\n",
    "def create_list( df,cols ):\n",
    "    names = set()\n",
    "    for col in cols:\n",
    "        for i in range(len(df)):\n",
    "            name = df.at[i,col]\n",
    "            if ( type(name) != float ):\n",
    "                names.add(name)\n",
    "    return sorted(list(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jgoto = goto.merge(genba, how='left', on='pj_no' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jgoto.to_csv(\"data/joinded_goto.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = jgoto.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの`feature_importances_`を確認すると、以下の改善の余地があることがわかった。\n",
    "- tt_msekiが第３位だが、欠損がtrain/test双方とも0.5%程度ある。\n",
    "    - genba/gotoを結合後、genbaのtt_mseki_avg_hbでtt_msekiを補完する。\n",
    "    - genbaのtt_mseki_min_hbとtt_mseki_max_hbの平均値で補完する\n",
    "    - 容積率80/100/150/200/300/400で欠損が残るので、それぞれの容積率の平均の対建物比率で算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最初の二つの項目は一つのラムダ式\n",
    "df['new_tt_mseki'] = df.apply(lambda x : x['tt_mseki'] if x['tt_mseki'] != 0 else x['tt_mseki_avg_hb'] if x['tt_mseki_avg_hb']!= 0 else x['tt_mseki_max_hb']  if x['tt_mseki_max_hb'] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 最後の一つを実現するアイデア\n",
    "# 1. new_tt_msekiがゼロ以外の集合に対して、容積率ごとに建物面積との比率を求める\n",
    "# 1-1 new_tt_mseki != 0の集合を作る\n",
    "# 1-2 容積率yoseki1でgroupbyする\n",
    "# 1-3 一つの容積率についてのDataFrameを取得\n",
    "# 1-4 当該DataFrameでtt_msekiとtc_msekiのそれぞれの合計値を求め、tt_mseki/tc_msekiの比ratioをともめる\n",
    "# 1-5 容積率とratioの組をdictに登録する\n",
    "# 1-6 1-4,1-5を繰り替えす\n",
    "# 2 new_tt_msekiがゼロの行について、欠損を補完する\n",
    "# 2-1 new_tt_msekiがゼロの行について、dictからratioを取得し、tc_msekiに乗じてnew_tt_msekiにいれる\n",
    "# 2-2 ratioが得られない場合には、tc_msekiと同じ値を入れておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1-1\n",
    "df2 = df[df['new_tt_mseki']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1-2\n",
    "yoseki_gr = df2.groupby('yoseki1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio_dict = {}\n",
    "for y in yoseki_gr.groups.keys():\n",
    "    # 1-3\n",
    "    d = yoseki_gr.get_group(y)\n",
    "    #1-4\n",
    "    total_tc = d['tc_mseki'].sum()\n",
    "    total_tt = d['tt_mseki'].sum()\n",
    "    ratio = total_tt/total_tc\n",
    "    #1-5\n",
    "    ratio_dict[y]= ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_tt_mseki( x ):\n",
    "    if x['tt_mseki'] != 0:\n",
    "        return x['tt_mseki']\n",
    "    yoseki = x['yoseki1']\n",
    "    ratio = ratio_dict[yoseki]\n",
    "    tt_mseki = x['tc_mseki'] * ratio\n",
    "    return tt_mseki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['new_tt_mseki'] = df.apply(calc_tt_mseki, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['new_tt_mseki']==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = tmp.groupby('yoseki1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = jgoto.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tt_mseki_pro'] = df.apply(lambda x : x['tt_mseki'] if x['tt_mseki'] != 0 else x['tt_mseki_avg_hb'] if x['tt_mseki_avg_hb']!= 0 else x['tt_mseki_max_hb']  if x['tt_mseki_max_hb'] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df['tt_mseki_pro']==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y80_avg = g.get_group(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(y80_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6/29 submit1.tsvで使ったRandomForestでは、変数の重要度はどうだったのだろうか\n",
    "今保留になっている号棟データの接道方位や現場データの道路の方位が上位なら、やはり実装が必要と言うことになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.externals import joblib\n",
    "model = joblib.load('data/randomforest_r1.model')\n",
    "x_train = pd.read_csv('data/processed_train_goto_x.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['id','pj_no'],axis=1)\n",
    "importance = pd.DataFrame(model.feature_importances_, index=x_train.columns)\n",
    "importance.to_csv(\"data/importance_submit1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⇒importance_submit1にコメント記入した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題で使うことになっている評価関数(Mean Absolute Percentage Error)をGridSearchCVで使うため、評価関数を自作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.array([100,100,100,100,100])\n",
    "p = np.array([90,110,100,100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (mean_absolute_percentage_error(t,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainとtestのデータから、同じダミー変数列を生成するためのコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_list( df1, df2, cols ):\n",
    "    names = set()\n",
    "    for col in cols:\n",
    "        for i in range(len(df1)):\n",
    "            name = df1.at[i,col]\n",
    "            if ( type(name) != float ):\n",
    "                names.add(name)\n",
    "        for i in range(len(df2)):\n",
    "            name = df2.at[i,col]\n",
    "            if ( type(name) != float ):\n",
    "                names.add(name)\n",
    "    return sorted(list(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv(\"data/train_genba.tsv\",sep='\\t')\n",
    "test = pd.read_csv(\"data/test_genba.tsv\",sep='\\t')\n",
    "hokakisei_list = create_list(train, test, ['hokakisei1','hokakisei2','hokakisei3','hokakisei4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(hokakisei_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train_goto.tsv\",sep='\\t')\n",
    "test = pd.read_csv(\"data/train_goto.tsv\",sep='\\t')\n",
    "kobetsu_list = create_list( train, test, ['kobetsu1','kobetsu2','kobetsu3','kobetsu4'])\n",
    "print(kobetsu_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 現場データのhokakisei1～4から出現するデータをリストにして返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 号棟データのkobetsu1～4をダミー変数化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_name(col, name):\n",
    "    if ( type(name) != float ):\n",
    "        col.add(name)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "train_goto = pd.read_csv(\"data/train_goto.tsv\",sep='\\t')\n",
    "df = train_goto.copy()\n",
    "\n",
    "cols = set()\n",
    "for i in range(len(df)):\n",
    "    put_name(cols, df.at[i,'kobetsu1'])\n",
    "    put_name(cols, df.at[i,'kobetsu2'])\n",
    "    put_name(cols, df.at[i,'kobetsu3'])\n",
    "    put_name(cols, df.at[i,'kobetsu4'])\n",
    "    \n",
    "kobetsu_map = {'信号近い':'信号前'}\n",
    "df['kobetsu1']=df['kobetsu1'].replace(kobetsu_map)\n",
    "df['kobetsu2']=df['kobetsu2'].replace(kobetsu_map)\n",
    "df['kobetsu3']=df['kobetsu3'].replace(kobetsu_map)\n",
    "df['kobetsu4']=df['kobetsu4'].replace(kobetsu_map)\n",
    "\n",
    "# ステップ２：\n",
    "kobetsu_dict = {}\n",
    "for x in cols:\n",
    "    kobetsu_dict[x] = np.zeros(len(df), dtype=np.int)\n",
    "\n",
    "# ステップ３：\n",
    "for i in range(len(df)):\n",
    "    name = df.at[i,'kobetsu1']\n",
    "    if ( type(name) != float):\n",
    "        kobetsu= kobetsu_dict[name]\n",
    "        kobetsu[i]=1\n",
    "    name = df.at[i,'kobetsu2']\n",
    "    if ( type(name) != float):\n",
    "        kobetsu= kobetsu_dict[name]\n",
    "        kobetsu[i]=1\n",
    "    name = df.at[i,'kobetsu3']\n",
    "    if ( type(name) != float):\n",
    "        kobetsu= kobetsu_dict[name]\n",
    "        kobetsu[i]=1\n",
    "    name = df.at[i,'kobetsu4']\n",
    "    if ( type(name) != float):\n",
    "        kobetsu= kobetsu_dict[name]\n",
    "        kobetsu[i]=1\n",
    "\n",
    "# 元のDataFrameとダミー変数化したものを連結\n",
    "new_genba = pd.concat([df, pd.DataFrame(kobetsu_dict)], axis=1)\n",
    "new_genba.to_csv(\"data/temp.csv\")\n",
    "\n",
    "# 不要になったkobetsu1～kobestu4を削除\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestを使って特徴量の重要度を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "x_train = pd.read_csv('data/processed_train_goto.csv')\n",
    "Y_train = pd.DataFrame(x_train['tc_tanka'])\n",
    "X_train = x_train.drop(['id','pj_no','tc_tanka'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(X_train.values, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(model.feature_importances_.reshape(1,len(model.feature_importances_)), columns=X_train.columns)\n",
    "importance.to_csv(\"data/importance1.csv\")\n",
    "# ⇒　横に長い一覧表になる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(model.feature_importances_, index=X_train.columns)\n",
    "importance.to_csv(\"data/importance2.csv\")\n",
    "# ⇒縦に長い一覧表になる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四つの列からなる法規制列のダミー変数化を行う\n",
    "ダミー変数化の前には、同一だが違う名前のついているデータを一意にする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "train_genba = pd.read_csv(\"data/train_genba.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 統一が必要なカラム\n",
    "- 公拡法　と　公有地拡大推進法　⇒　公拡法へ\n",
    "- 埋蔵文化財　と　文化財保護法　と　文化財保護法（埋蔵文化財）　⇒　埋蔵文化財へ\n",
    "- 景観法　と　景観地区　⇒　景観法へ\n",
    "- 東日本震災復興特　と　東日本大震災復興特別区域法　⇒　東日本震災復興特　へ\n",
    "- 農地法　と　農地法届出要　⇒　農地法　へ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 法規制のうち、出現回数が1,2回のものがある。⇒　出現階数が４以上のものに絞ると次のように。本当に絞るかはRandomForestの重要度を見てから決めることにする。\n",
    "- 公拡法 あわせて１９回\n",
    "- 区画整理法 4回\n",
    "- 国土法　11回\n",
    "- 埋蔵文化財 75+2+39回\n",
    "- 景観法 549+23回\n",
    "- 東日本震災復興特 7+1回\n",
    "- 河川法 10回\n",
    "- 自然公園法 9回\n",
    "- 航空法 19回\n",
    "- 農地法 270+15回\n",
    "- 風致地区 １９回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ステップ１：　hokaisei1〜4に対して法規制の名称の統一をする \n",
    "# ステップ２：対象とする法規制のダミー変数列を作る\n",
    "# ステップ3：ダミー変数化する\n",
    "\n",
    "def put_name(col, name):\n",
    "    if ( type(name) != float ):\n",
    "        col.add(name)\n",
    "\n",
    "# ステップ１：\n",
    "train_genba = pd.read_csv(\"data/train_genba.tsv\",sep='\\t')\n",
    "df = train_genba.copy()\n",
    "kisei_map = {'公有地拡大推進法':'公拡法', '文化財保護法':'埋蔵文化財', '文化財保護法（埋蔵文化財）':'埋蔵文化財', '景観地区':'景観法','東日本大震災復興特別区域法':'東日本震災復興特', '農地法届出要':'農地法　'}\n",
    "#kisei_map = {'公有地拡大推進法':'公拡法', '文化財保護法':'埋蔵文化財', '文化財保護法（埋蔵文化財）　':'埋蔵文化財','景観地区':'景観法','東日本大震災復興特別区域法':'東日本震災復興特'}\n",
    "\n",
    "df['hokakisei1']=df['hokakisei1'].replace(kisei_map)\n",
    "df['hokakisei2']=df['hokakisei2'].replace(kisei_map)\n",
    "df['hokakisei3']=df['hokakisei3'].replace(kisei_map)\n",
    "df['hokakisei4']=df['hokakisei4'].replace(kisei_map)\n",
    "\n",
    "cols = set()\n",
    "for i in range(len(train_genba)):\n",
    "    put_name(cols, df.at[i,'hokakisei1'])\n",
    "    put_name(cols, df.at[i,'hokakisei2'])\n",
    "    put_name(cols, df.at[i,'hokakisei3'])\n",
    "    put_name(cols, df.at[i,'hokakisei4'])\n",
    "\n",
    "# ステップ２：\n",
    "kisei_dict = {}\n",
    "for x in cols:\n",
    "    kisei_dict[x] = np.zeros(len(df), dtype=np.int)\n",
    "\n",
    "# ステップ３：\n",
    "for i in range(len(df)):\n",
    "    name = df.at[i,'hokakisei1']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = df.at[i,'hokakisei2']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = df.at[i,'hokakisei3']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = df.at[i,'hokakisei4']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "\n",
    "# 元のDataFrameとダミー変数化したものを連結\n",
    "new_genba = pd.concat([df, pd.DataFrame(kisei_dict)], axis=1)\n",
    "new_genba.to_csv(\"data/temp.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = set()\n",
    "for i in range(len(train_genba)):\n",
    "    name = train_genba.at[i,'hokakisei1']\n",
    "    if ( type(name) != float):\n",
    "        cols.add(name)\n",
    "    name = train_genba.at[i,'hokakisei2']\n",
    "    if ( type(name) != float):\n",
    "        cols.add(name)\n",
    "    name = train_genba.at[i,'hokakisei3']\n",
    "    if ( type(name) != float):\n",
    "        cols.add(name)\n",
    "    name = train_genba.at[i,'hokakisei4']\n",
    "    if ( type(name) != float):\n",
    "        cols.add(name)\n",
    "\n",
    "kisei_dict = {}\n",
    "for x in cols:\n",
    "    kisei_dict[x] = np.zeros(len(train_genba),dtype=np.int)\n",
    "    \n",
    "for i in range(len(train_genba)):\n",
    "    name = train_genba.at[i,'hokakisei1']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = train_genba.at[i,'hokakisei2']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = train_genba.at[i,'hokakisei3']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "    name = train_genba.at[i,'hokakisei4']\n",
    "    if ( type(name) != float):\n",
    "        kisei = kisei_dict[name]\n",
    "        kisei[i]=1\n",
    "\n",
    "kisei_df = pd.DataFrame(kisei_dict)\n",
    "kisei_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " train_genba.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_tgenba = pd.concat([train_genba, kisei_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_tgenba.to_csv(\"data/temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(kisei_dict).to_csv(\"data/temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6/22の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['pj']=prod_goto['pj_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tc_mseki'] = prod_goto['tc_mseki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['tt_mseki', 'fukuin']]=prod_goto[['tt_mseki','fukuin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからモデル作成と予測をするコードを書く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('data/processed_train_goto.csv')\n",
    "Y_train = pd.DataFrame(x_train['tc_tanka'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = x_train.drop(['id','pj_no','tc_tanka'],axis=1)\n",
    "X_train = X_train.values\n",
    "Y_train = Y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoostは時間かかりすぎ\n",
    "#  XGB = XGBClassifier(n_estimater=500,n_jobs=-1)\n",
    "# XGB.fit(X_train, Y_train)\n",
    "#\n",
    "# ⇒　RandomForestで重要度を見てから、不要な特徴量を落とすことにする\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6/20の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_genba.copy()\n",
    "df['gk_yoc_tm'] = df['gk_yoc_tm'].fillna(df['gk_yoc_tm'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(prod_goto.isnull().sum()).to_csv(\"data/null_check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "test_goto = pd.read_csv(\"data/processed_test_goto.csv\")\n",
    "pd.DataFrame(test_goto.isnull().sum()).to_csv(\"data/null_check_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 確認の結果、次のカラムにNULLを含む\n",
    "#### chiseki_kb_hb,kaoku_hb, mseki_rd_hb, mseki_dp_hb, chiseki_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # 間口(magutchi)\n",
    "    # 幅員と同じように補完する。\n",
    "    df['magutchi'] = df['magutchi'].fillna(0)\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'magutchi'] ==0 ) :\n",
    "            df.at[i,'magutchi'] = df.at[i,'road1_mg']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6/18,19の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_goto.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genba = pd.read_csv(\"data/processed_train_genba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf=df.merge(genba, how=\"left\", on='pj_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newdf.to_csv(\"data/joined_data.csv\")\n",
    "df = newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fukuin'] = df['fukuin'].fillna(0)\n",
    "for i in range(len(df)):\n",
    "    if ( df.at[i,'fukuin'] ==0 ) :\n",
    "        df.at[i,'fukuin'] = df.at[i,'road1_fi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    df['magutchi'] = df['magutchi'].fillna(0)\n",
    "    for i in range(len(df)):\n",
    "        if ( df.at[i,'magutchi'] ==0 ) :\n",
    "            df.at[i,'magutchi'] = df.at[i,'road1_mg']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['setsudo_hi' ] = df['setsudo_hi'].fillna('unknown')\n",
    "for i in range(len(df)):\n",
    "    if ( df.at[i,'setsudo_hi']=='unknown'):\n",
    "        df.at[i.'setsudo_hi']=df.at[i,'road1_hk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 元データでjoinしておく\n",
    "import pandas as pd\n",
    "genba = pd.read_csv(\"data/train_genba.tsv\", sep='\\t')\n",
    "goto = pd.read_csv(\"data/train_goto.tsv\", sep='\\t')\n",
    "df = goto.merge(genba, how=\"left\", on='pj_no')\n",
    "df.to_csv(\"data/org_joined_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pj_no</th>\n",
       "      <th>keiyaku_pr</th>\n",
       "      <th>tc_mseki</th>\n",
       "      <th>tt_mseki</th>\n",
       "      <th>levelplan</th>\n",
       "      <th>fukuin</th>\n",
       "      <th>road_st</th>\n",
       "      <th>magutchi</th>\n",
       "      <th>setsudo_hi</th>\n",
       "      <th>...</th>\n",
       "      <th>bas_toho1</th>\n",
       "      <th>eki_kyori1</th>\n",
       "      <th>bastei_nm1</th>\n",
       "      <th>teiho1</th>\n",
       "      <th>rosen_nm2</th>\n",
       "      <th>eki_nm2</th>\n",
       "      <th>bas_toho2</th>\n",
       "      <th>eki_kyori2</th>\n",
       "      <th>bastei_nm2</th>\n",
       "      <th>teiho2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0000</td>\n",
       "      <td>0</td>\n",
       "      <td>39800000</td>\n",
       "      <td>109.26</td>\n",
       "      <td>104.43</td>\n",
       "      <td>2F/4LDK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>問題なし</td>\n",
       "      <td>9.9</td>\n",
       "      <td>東</td>\n",
       "      <td>...</td>\n",
       "      <td>徒歩</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_0001</td>\n",
       "      <td>1</td>\n",
       "      <td>22300000</td>\n",
       "      <td>136.11</td>\n",
       "      <td>105.16</td>\n",
       "      <td>2F/4LDK</td>\n",
       "      <td>4.2</td>\n",
       "      <td>問題なし</td>\n",
       "      <td>9.3</td>\n",
       "      <td>北西</td>\n",
       "      <td>...</td>\n",
       "      <td>徒歩</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_0002</td>\n",
       "      <td>2</td>\n",
       "      <td>19800000</td>\n",
       "      <td>87.07</td>\n",
       "      <td>85.94</td>\n",
       "      <td>2F/4LDK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>問題なし</td>\n",
       "      <td>11.1</td>\n",
       "      <td>東</td>\n",
       "      <td>...</td>\n",
       "      <td>徒歩</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_0003</td>\n",
       "      <td>3</td>\n",
       "      <td>33990000</td>\n",
       "      <td>163.75</td>\n",
       "      <td>105.98</td>\n",
       "      <td>2F/4LDK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>問題なし</td>\n",
       "      <td>10.5</td>\n",
       "      <td>南</td>\n",
       "      <td>...</td>\n",
       "      <td>徒歩</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_0004</td>\n",
       "      <td>4</td>\n",
       "      <td>30800000</td>\n",
       "      <td>111.51</td>\n",
       "      <td>89.01</td>\n",
       "      <td>2F/4LDK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>問題なし</td>\n",
       "      <td>13.5</td>\n",
       "      <td>北</td>\n",
       "      <td>...</td>\n",
       "      <td>徒歩</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  pj_no  keiyaku_pr  tc_mseki  tt_mseki levelplan  fukuin  \\\n",
       "0  train_0000      0    39800000    109.26    104.43   2F/4LDK     4.0   \n",
       "1  train_0001      1    22300000    136.11    105.16   2F/4LDK     4.2   \n",
       "2  train_0002      2    19800000     87.07     85.94   2F/4LDK     4.0   \n",
       "3  train_0003      3    33990000    163.75    105.98   2F/4LDK     4.0   \n",
       "4  train_0004      4    30800000    111.51     89.01   2F/4LDK     4.0   \n",
       "\n",
       "  road_st  magutchi setsudo_hi  ...   bas_toho1 eki_kyori1 bastei_nm1  teiho1  \\\n",
       "0    問題なし       9.9          東  ...          徒歩         17        NaN     NaN   \n",
       "1    問題なし       9.3         北西  ...          徒歩         13        NaN     NaN   \n",
       "2    問題なし      11.1          東  ...          徒歩         27        NaN     NaN   \n",
       "3    問題なし      10.5          南  ...          徒歩         18        NaN     NaN   \n",
       "4    問題なし      13.5          北  ...          徒歩          7        NaN     NaN   \n",
       "\n",
       "   rosen_nm2 eki_nm2 bas_toho2 eki_kyori2 bastei_nm2 teiho2  \n",
       "0        NaN     NaN       NaN        NaN        NaN    NaN  \n",
       "1        NaN     NaN       NaN        NaN        NaN    NaN  \n",
       "2        NaN     NaN       NaN        NaN        NaN    NaN  \n",
       "3        NaN     NaN       NaN        NaN        NaN    NaN  \n",
       "4        NaN     NaN       NaN        NaN        NaN    NaN  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[146,'fukuin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fukuin'] = df['fukuin'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['fukuin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### いつのだかわからないコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_genba.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['bus', 'walk']] = df.apply(calculateLogistics, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[0:20,['bas_toho1','eki_kyori1','teiho1','bus','walk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下記は6/16夜の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateLogistics(x):\n",
    "    if ( x['bas_toho1'] == 'バス' ):\n",
    "        bus = x['eki_kyori1']\n",
    "        walk = x['teiho1']\n",
    "    else:\n",
    "        bus = 0\n",
    "        walk = x['eki_kyori1']\n",
    "    \n",
    "    return pd.Series([bus, walk])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下記は6/16の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['yoto','kempei','yoseki']] = df.apply(select_yoto, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isnan(df.loc[0,'yoto2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(df.loc[26,'yoto2'])==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[20,'shu_soon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['shu_soon'].map({'○':1, np.NaN:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_yoto(x):\n",
    "    if ( type(x['yoto2']) == str ):\n",
    "        yoto =x['yoto2']\n",
    "        kempei = x['kempei2']\n",
    "        yoseki =x['yoseki2']\n",
    "    else:\n",
    "        yoto =x['yoto1']\n",
    "        kempei =x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    \"\"\"\n",
    "    if ( np.isnan(x['yoto2'])):\n",
    "        yoto =x['yoto1']\n",
    "        kempei =x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    else:\n",
    "        yoto =x['yoto2']\n",
    "        kempei = x['kempei2']\n",
    "        yoseki =x['yoseki2']\n",
    "    \"\"\"\n",
    "    \"\"\"\"\n",
    "    if ( x['yoto2']==np.nan):\n",
    "        yoto =x['yoto1']\n",
    "        kenpei =x['kempek1']\n",
    "        yoseki =x['yoseki1']\n",
    "    elif ( x['kempei1']<x['kempei2']):\n",
    "        yoto =x['yoto1']\n",
    "        kempei = x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    else:\n",
    "        yoto = x['yoto']=x['yoto1']\n",
    "        kempei = x['kempei']=x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    \"\"\"\n",
    "    return pd.Series([yoto, kempei, yoseki])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下記は6/15の作業"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('jukyo',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['yoto'], df['kempei'],df['yoseki']= df.apply(select_yoto,axis=1)\n",
    "df[['yoto','kempei','yoseki']] = df.apply(select_yoto,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['josui'] = df.apply(lambda x: 1 if x['josui']=='公営' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['gesui'] = df.apply(lambda x: 1 if x['gesui']=='公共下水' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['gas'] = df.apply(lambda x: 2 if x['gas'] =='都市ガス' else 1 if x['gas'] == '集中プロパン' else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['chiseki_diff'] = df['chiseki_kb_hb']-df['chiseki_js_hb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.get_dummies(df[['usui']],drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.merge(df, a, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, pd.get_dummies(df[['usui']],drop_first = False), left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.fillna({'tateuri_su': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, pd.get_dummies(df[['road1_hk','road1_sb']],drop_first = False), left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['road_num']=df.apply(lambda x: 4 if x['road4_hk']!=np.nan else 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['road_num']=df.apply(lambda x: 4 if x['road4_fi']!=0 else 3 if x['road3_fi']!=0 else 2 if x['road2_fi']!=0 else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['road_num']=df.apply(lambda x: 4 if not math.isnan(x['road4_fi']) else 3 if not math.isnan(x['road3_fi']) else 2 if not math.isnan(x['road2_fi']) else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['toshikuiki']=df['toshikuiki2'].fillna('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['toshikuiki'] = df.apply(lambda x: x['toshikuiki1'] if x['toshikuiki']==\"empty\" else x['toshikuiki2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['toshikuiki']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[1549,'toshikuiki2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_yoto(x):\n",
    "    if ( x['yoto2']==np.nan):\n",
    "        yoto =x['yoto1']\n",
    "        kenpei =x['kempek1']\n",
    "        yoseki =x['yoseki1']\n",
    "    elif ( x['kempei1']<x['kempei2']):\n",
    "        yoto =x['yoto1']\n",
    "        kempei = x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    else:\n",
    "        yoto = x['yoto']=x['yoto1']\n",
    "        kempei = x['kempei']=x['kempei1']\n",
    "        yoseki =x['yoseki1']\n",
    "    return pd.Series([yoto, kempei, yoseki])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
