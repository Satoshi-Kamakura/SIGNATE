{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validationを取り入れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# 事前準備処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "## 　ハイパーパラメタ\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v12.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v12.csv\")\n",
    "train_g = pd.read_csv(\"data/train_genba.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train_x, train_y, org_genbaを受けとり、genbaデータで分割を行ったX_train, X_eval, Y_train, Y_evalを返す\n",
    "from sklearn.model_selection import train_test_split\n",
    "def split_by_genba( genba, train_x, train_y, train_s, test_s, rs ):\n",
    "    y = genba['pj_no']\n",
    "    x = genba.drop(['pj_no'],axis=1)\n",
    "    train_y_with_pj = pd.merge(train_y, train_x[['id','pj_no']], how='inner', on='id')\n",
    "    pj_train, pj_eval, genba_train, genba_eval = train_test_split(y, x, train_size = train_s, test_size = test_s, random_state = rs)\n",
    "    X_train = pd.merge(pj_train, train_x,  how='inner', on='pj_no')\n",
    "    X_eval = pd.merge(pj_eval, train_x,  how='inner', on='pj_no')\n",
    "    Y_train = pd.merge(pj_train, train_y_with_pj,  how='inner', on='pj_no').drop(['pj_no'],axis=1)\n",
    "    Y_eval = pd.merge(pj_eval, train_y_with_pj,  how='inner', on='pj_no').drop(['pj_no'],axis=1)\n",
    "    \n",
    "    return(X_train, X_eval, Y_train, Y_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, Y_train, Y_eval = split_by_genba( train_g, train_x, train_y, train_s = 0.8, test_s = 0.2, rs = 11)\n",
    "print(len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1331772230, 10.139171265157536)\n",
      "(1628932642, 10.119895243840316)\n",
      "(1804610804, 10.750349810344487)\n",
      "(1248366107, 10.133013824816778)\n",
      "(1209639770, 11.6642383455501)\n",
      "(1262238905, 10.802457851738122)\n",
      "(305833057, 11.375713745279832)\n",
      "(1939017787, 11.116624664611042)\n",
      "(903097299, 11.189529106416034)\n",
      "(1837115670, 10.080631547187274)\n"
     ]
    }
   ],
   "source": [
    "error = []\n",
    "models = []\n",
    "for i in range(10):\n",
    "    s = np.random.randint(2143486417,high=None)\n",
    "    #X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, test_size=0.2, random_state = s)\n",
    "    X_train, X_eval, Y_train, Y_eval = split_by_genba(train_g, train_x, train_y, train_s=0.8, test_s=0.2, rs = s)\n",
    "    \n",
    "    x_train = X_train.drop(['id','pj_no'],axis=1)\n",
    "    y_train = Y_train.drop(['id'],axis=1)\n",
    "    x_eval = X_eval.drop(['id','pj_no'],axis=1)\n",
    "\n",
    "    model = XGBRegressor(**params, seed=19711022, n_jobs=-1)\n",
    "    model.fit(x_train, y_train )\n",
    "    pred = model.predict(x_eval)\n",
    "    \n",
    "    e = mean_absolute_percentage_error(Y_eval['keiyaku_pr'].values, pred)\n",
    "    \n",
    "    d = (s, e)\n",
    "    print(d)\n",
    "    error.append(d)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = pd.DataFrame(pred, columns=['predict_pr'])\n",
    "Y_eval_pred = pd.concat([Y_eval, predict_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred['mean_error(abs)']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['predict_pr'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['mean_error']=(Y_eval_pred['keiyaku_pr']-Y_eval_pred['predict_pr'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['mean_error(abs)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.merge(X_eval, Y_eval_pred, how='inner', on = 'id')\n",
    "out.to_csv(\"data/difference_v12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x_v12.csv\")\n",
    "x_test = test_x.drop(['id','pj_no'],axis=1)\n",
    "\n",
    "model = models[6]\n",
    "ans = model.predict(x_test)\n",
    "\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(ans).astype(np.int64)\n",
    "submit.to_csv('data/submit_v12_worst.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[9]\n",
    "ans = model.predict(x_test)\n",
    "\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(ans).astype(np.int64)\n",
    "submit.to_csv('data/submit_v12_best.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V9での実施事項\n",
    "- 土地売りと建て売りとで分けて訓練、予測を行う\n",
    "\n",
    "#### ⇒効果ないことが判明した\n",
    "#### それよりも、効果のないカラムを削除した方が良いのかもしれない\n",
    "\n",
    "# V8での提出結果\n",
    "MAPE ... 10.46\n",
    "\n",
    "### 気づき事項\n",
    "- 路線ごとにerrorが異なるのではないか？\n",
    "- 上記の結果では、路線ごとにモデルを作るべきなのかもしれない\n",
    "- 訓練データでのMAPEが3.56に対して、土地売りだと4.87。土地売りは別モデルとして学習すべき？\n",
    "- 異常値は除去すべきかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7/20 実施事項\n",
    "- V9データと、XGBoostの固定のハイパーパラメタを使い、XGBoostに与える乱数を変更して複数のモデルを作ることで、精度が向上するかを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# 事前準備処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "def learn( train_x, train_y, params, s ):\n",
    "    model = XGBRegressor(**params, seed=s, n_jobs=-1)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v11.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v11.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "## 　ハイパーパラメタ\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "x_train = X_train.drop(['id','pj_no'],axis=1)\n",
    "y_train = Y_train.drop(['id'],axis=1)\n",
    "x_eval = X_eval.drop(['id','pj_no'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "models= []\n",
    "preds = []\n",
    "\n",
    "for i in range(30):\n",
    "    print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = learn(x_train, y_train, params, np.random.randint(2143486417,high=None))\n",
    "    pred = model.predict(x_eval)\n",
    "    models.append(model)\n",
    "    preds.append(pred)\n",
    "    end = time.perf_counter()\n",
    "    print('finished ', 'elapsed time : ', end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred = pd.concat([Y_eval.reset_index(), df], axis=1)\n",
    "Y_eval_pred['mean_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['mean'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['mean_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out = pd.DataFrame(Y_eval_pred[['id','keiyaku_pr','mean','mean_error']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out = pd.merge(eval_out, X_eval,on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_out.to_csv(\"data/submit_v11_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### これで次の提出データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x_v11.csv\")\n",
    "x_test = test_x.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(anss).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=df['mean']\n",
    "submit.to_csv('data/submit_v11.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_evalで再現テストする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_eval.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(anss).T\n",
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred2=pd.concat([Y_eval.reset_index(), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred2['error']=abs(Y_eval_pred2['keiyaku_pr']-Y_eval_pred2['mean'])/Y_eval_pred2['keiyaku_pr']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred2['error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_trainで再現テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_train.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(anss).T\n",
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)\n",
    "Y_eval_pred2=pd.concat([Y_train.reset_index(), df], axis=1)\n",
    "Y_eval_pred2['error']=abs(Y_eval_pred2['keiyaku_pr']-Y_eval_pred2['mean'])/Y_eval_pred2['keiyaku_pr']*100\n",
    "Y_eval_pred2['error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データ全体で予測し、訓練データと結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_x.drop(['id','pj_no'],axis=1)\n",
    "anss = []\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)\n",
    "df = pd.DataFrame(anss).T\n",
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)\n",
    "df2=pd.concat([train_y.reset_index(), df], axis=1)\n",
    "df2['error']=abs(df2['keiyaku_pr']-df2['mean'])/df2['keiyaku_pr']*100\n",
    "df2['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.concat([train_y.reset_index(), df2['mean'],df2['error']], axis=1)\n",
    "genba = pd.read_csv(\"data/train_genba.tsv\", sep='\\t')\n",
    "goto = pd.read_csv(\"data/train_goto.tsv\", sep='\\t')\n",
    "df4 = pd.merge(df3, goto, on='id', how='left')\n",
    "df5 = pd.merge(df4, genba, on='pj_no', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.to_csv(\"data/submit_v11_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as pdp\n",
    "pdp.ProfileReport(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## シリアライズしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"model_V11.pkl\",\"wb\")\n",
    "pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デシリアライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(\"model_V11.pkl\", \"rb\")\n",
    "models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数モデルから重要度を取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v11.csv\").drop(['id','pj_no'],axis=1)\n",
    "index = models[0].feature_importances_+models[1].feature_importances_\n",
    "importances = models[0].feature_importances_\n",
    "for i in range(len(models)-1):\n",
    "    importances += models[i+1].feature_importances_\n",
    "mean = importances / len(models)\n",
    "df = pd.DataFrame(mean, index=train_x.columns)\n",
    "df.to_csv(\"data/importance_V11.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = models[0].feature_importances_\n",
    "for i in range(len(models)-1):\n",
    "    importances += models[i+1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = importances / len(models)\n",
    "df = pd.DataFrame(mean, index=x_train.columns)\n",
    "df2 = pd.DataFrame(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 7/20 使わなくなったコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_values(x):\n",
    "    return( pd.Series([x.min(), x.max(), x.mean(), x.median(), x.std()]))\n",
    "\n",
    "df[['min', 'max', 'mean','median','std']]=df.apply(calc_values, axis=1)\n",
    "\n",
    "Y_eval_pred = pd.concat([Y_eval.reset_index(), df], axis=1)\n",
    "\n",
    "Y_eval_pred['mean_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['mean'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['median_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['median'])/Y_eval_pred['keiyaku_pr']*100\n",
    "\n",
    "Y_eval_pred['mean_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# 事前準備処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v9.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v9.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn( train_x, train_y, params, s ):\n",
    "    model = XGBRegressor(**params, seed=s, n_jobs=-1)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v9.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v9.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "## 土地売り・建て売りに分解せずに同じことをしてみる\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "model = learn(X_train.drop(['id','pj_no'],axis=1), Y_train.drop(['id'],axis=1), params, 42)\n",
    "pred_y = model.predict(X_eval.drop(['id','pj_no'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_all = pd.DataFrame(X_eval[['id','levelplan_土地売り']].copy().reset_index(drop=True))\n",
    "Y_pred_all['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_percentage_error(Y_eval_pred['keiyaku_pr'].values, Y_eval_pred['pred_keiyaku_pr'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Y_eval_pred\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/processed_train_goto_x_v9.csv\"),on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以降はむだだったコード。建て売りか土地売りかで別モデルを作ったが、結局意味はなかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 土地売りと建て売りとにデータを分割\n",
    "X_train_tateuri = X_train[X_train['levelplan_土地売り']==0]\n",
    "X_train_tochiuri = X_train[X_train['levelplan_土地売り']==1]\n",
    "Y_train_tateuri = Y_train[X_train['levelplan_土地売り']==0]\n",
    "Y_train_tochiuri = Y_train[X_train['levelplan_土地売り']==1]\n",
    "\n",
    "X_eval_tateuri = X_eval[X_eval['levelplan_土地売り']==0]\n",
    "X_eval_tochiuri = X_eval[X_eval['levelplan_土地売り']==1]\n",
    "Y_eval_tateuri = Y_eval[X_eval['levelplan_土地売り']==0]\n",
    "Y_eval_tochiuri = Y_eval[X_eval['levelplan_土地売り']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 土地売り以外のlevelplanを削除してみる\n",
    "X_train_1 = X_train.drop(['levelplan_1F/2LDK','levelplan_1F/3LDK','levelplan_1F/4LDK','levelplan_1F/4LDK+S','levelplan_1F/5LDK'],axis=1)\n",
    "X_train_2 = X_train_1.drop(['levelplan_2F/2LDK','levelplan_2F/2LDK+S','levelplan_2F/3DK','levelplan_2F/3LDK','levelplan_2F/3LDK+2S','levelplan_2F/3LDK+S','levelplan_2F/4DK','levelplan_2F/4LDK','levelplan_2F/4LDK+S','levelplan_2F/5DK','levelplan_2F/5LDK'],axis=1)\n",
    "X_train_3 = X_train_2.drop(['levelplan_3F/2LDK','levelplan_3F/2LDK+2S','levelplan_3F/2LDK+S','levelplan_3F/3DK','levelplan_3F/3LDK','levelplan_3F/3LDK+2S','levelplan_3F/3LDK+S','levelplan_3F/4DK','levelplan_3F/4LDK','levelplan_3F/4LDK+S','levelplan_3F/5LDK'],axis=1)\n",
    "\n",
    "X_eval_1 = X_eval.drop(['levelplan_1F/2LDK','levelplan_1F/3LDK','levelplan_1F/4LDK','levelplan_1F/4LDK+S','levelplan_1F/5LDK'],axis=1)\n",
    "X_eval_2 = X_eval_1.drop(['levelplan_2F/2LDK','levelplan_2F/2LDK+S','levelplan_2F/3DK','levelplan_2F/3LDK','levelplan_2F/3LDK+2S','levelplan_2F/3LDK+S','levelplan_2F/4DK','levelplan_2F/4LDK','levelplan_2F/4LDK+S','levelplan_2F/5DK','levelplan_2F/5LDK'],axis=1)\n",
    "X_eval_3 = X_eval_2.drop(['levelplan_3F/2LDK','levelplan_3F/2LDK+2S','levelplan_3F/2LDK+S','levelplan_3F/3DK','levelplan_3F/3LDK','levelplan_3F/3LDK+2S','levelplan_3F/3LDK+S','levelplan_3F/4DK','levelplan_3F/4LDK','levelplan_3F/4LDK+S','levelplan_3F/5LDK'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ルーチンを呼び出す。\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "tateuri_model = learn(X_train_tateuri.drop(['id','pj_no','levelplan_土地売り'],axis=1), Y_train_tateuri.drop(['id'],axis=1), params, 42)\n",
    "tochiuri_model = learn(X_train_tochiuri.drop(['id','pj_no','levelplan_土地売り'],axis=1), Y_train_tochiuri.drop(['id'],axis=1), params, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測する\n",
    "pred_y_tateuri = tateuri_model.predict(X_eval_tateuri.drop(['id','pj_no','levelplan_土地売り'],axis=1))\n",
    "pred_y_tochiuri = tochiuri_model.predict(X_eval_tochiuri.drop(['id','pj_no','levelplan_土地売り'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameの形で予測値を作成する\n",
    "Y_pred_tateuri = pd.DataFrame(X_eval_tateuri['id'].copy().reset_index(drop=True))\n",
    "Y_pred_tateuri['pred_keiyaku_pr'] = pd.Series(pred_y_tateuri)\n",
    "Y_pred_tochiuri = pd.DataFrame(X_eval_tochiuri['id'].copy().reset_index(drop=True))\n",
    "Y_pred_tochiuri['pred_keiyaku_pr'] = pd.Series(pred_y_tochiuri)\n",
    "Y_pred_all = pd.concat([Y_pred_tateuri, Y_pred_tochiuri])\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn(X_train_3.drop(['id','pj_no'],axis=1), Y_train.drop(['id'],axis=1), params, 42)\n",
    "pred_y = model.predict(X_eval_3.drop(['id','pj_no'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_all = pd.DataFrame(X_eval_3[['id','levelplan_土地売り']].copy().reset_index(drop=True))\n",
    "Y_pred_all['pred_keiyaku_pr'] = pd.Series(pred_y)\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_percentage_error(Y_eval_pred['keiyaku_pr'].values, Y_eval_pred['pred_keiyaku_pr'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 共通処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v8.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v8.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_eval.to_csv(\"data/X_eval.csv\", index=False)\n",
    "Y_train.to_csv(\"data/Y_train.csv\", index=False)\n",
    "Y_eval.to_csv(\"data/Y_eval.csv\", index=False)\n",
    "\n",
    "train_x = pd.read_csv('data/X_train.csv').drop(['id','pj_no'],axis=1)\n",
    "train_y = pd.read_csv('data/Y_train.csv').drop(['id'],axis=1)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "print(f\"start learning...\")\n",
    "xgboost_opt = XGBRegressor(**params, seed=42, n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "xgboost_opt.fit(train_x, train_y)\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/processed_train_goto_x_v8.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/processed_train_goto_y_v8.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/processed_train_goto_y_v8.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/processed_train_goto_x_v8.csv\"),on='id')\n",
    "output.to_csv(\"data/train_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/Y_eval.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/X_eval.csv\"),on='id')\n",
    "output.to_csv(\"data/eval_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(xgboost_opt.feature_importances_, index=eval_x.columns)\n",
    "importance.to_csv(\"data/feature_importances_V8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x_v8.csv\")\n",
    "test_pred = xgboost_opt.predict(test_x.drop(['id','pj_no'],axis=1))\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(test_pred).astype(np.int64)\n",
    "submit.to_csv('data/submit_v8.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimatorsが700のケースでsubmitしてみることにする(7/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")\n",
    "test_pred = xgboost_opt.predict(test_x.drop(['id','pj_no'],axis=1))\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(test_pred).astype(np.int64)\n",
    "submit.to_csv('data/submit4.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここからSageMaker用のデータを作る処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv')\n",
    "train_y = pd.read_csv('data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = pd.concat([train_y.drop(['id','keiyaku_pr','tc_mseki'],axis=1),train_x.drop(['id','pj_no'],axis=1)],axis=1)\n",
    "train_input.to_csv('data/sagemaker_input.csv', header=None, index=False)\n",
    "eval_x = pd.read_csv('data/X_eval.csv')\n",
    "eval_x.drop(['id','pj_no'],axis=1).to_csv('data/sagemaker_eval_input.csv',header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMakerの出力から精度を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_y = pd.read_csv('data/sagemaker_eval_input.csv.out', header=None)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( mean_absolute_percentage_error(ans_y.values,pred2_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMaker用予測データを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_x.drop(['id','pj_no'],axis=1)\n",
    "test_input.to_csv('data/sagemaker_test_input.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker出力からsubmit用データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanka = pd.read_csv(\"data/sagemaker_test_input.csv.out\", header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id', 'tc_mseki']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['tanka_pr']=tanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['price']=(submit['tc_mseki']*submit['tanka_pr']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.loc[:,['id','price']].to_csv('data/submit3.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
