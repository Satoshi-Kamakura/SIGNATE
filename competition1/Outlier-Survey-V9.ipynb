{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V9での実施事項\n",
    "- 土地売りと建て売りとで分けて訓練、予測を行う\n",
    "\n",
    "#### ⇒効果ないことが判明した\n",
    "#### それよりも、効果のないカラムを削除した方が良いのかもしれない\n",
    "\n",
    "# V8での提出結果\n",
    "MAPE ... 10.46\n",
    "\n",
    "### 気づき事項\n",
    "- 路線ごとにerrorが異なるのではないか？\n",
    "- 上記の結果では、路線ごとにモデルを作るべきなのかもしれない\n",
    "- 訓練データでのMAPEが3.56に対して、土地売りだと4.87。土地売りは別モデルとして学習すべき？\n",
    "- 異常値は除去すべきかもしれない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7/20 実施事項\n",
    "- V9データと、XGBoostの固定のハイパーパラメタを使い、XGBoostに与える乱数を変更して複数のモデルを作ることで、精度が向上するかを試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# 事前準備処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "def learn( train_x, train_y, params, s ):\n",
    "    model = XGBRegressor(**params, seed=s, n_jobs=-1)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v9.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v9.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "## 　ハイパーパラメタ\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "x_train = X_train.drop(['id','pj_no'],axis=1)\n",
    "y_train = Y_train.drop(['id'],axis=1)\n",
    "x_eval = X_eval.drop(['id','pj_no'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter :  0  starting... finished  elapsed time :  15.24500465500023\n",
      "iter :  1  starting... finished  elapsed time :  16.666418582000915\n",
      "iter :  2  starting... finished  elapsed time :  16.273433882000973\n",
      "iter :  3  starting... finished  elapsed time :  16.601685476001876\n",
      "iter :  4  starting... finished  elapsed time :  16.38030853899909\n",
      "iter :  5  starting... finished  elapsed time :  15.965131813998596\n",
      "iter :  6  starting... finished  elapsed time :  15.863947455000016\n",
      "iter :  7  starting... finished  elapsed time :  15.404040953999356\n",
      "iter :  8  starting... finished  elapsed time :  15.285357493998163\n",
      "iter :  9  starting... finished  elapsed time :  15.283609405996685\n",
      "iter :  10  starting... finished  elapsed time :  15.39643827799955\n",
      "iter :  11  starting... finished  elapsed time :  16.283910065998498\n",
      "iter :  12  starting... finished  elapsed time :  16.247310938000737\n",
      "iter :  13  starting... finished  elapsed time :  15.810116494001704\n",
      "iter :  14  starting... finished  elapsed time :  16.6561732629998\n",
      "iter :  15  starting... finished  elapsed time :  15.59247883200078\n",
      "iter :  16  starting... finished  elapsed time :  15.596716539999761\n",
      "iter :  17  starting... finished  elapsed time :  15.508738874999835\n",
      "iter :  18  starting... finished  elapsed time :  15.511535514997377\n",
      "iter :  19  starting... finished  elapsed time :  15.503404235001653\n",
      "iter :  20  starting... finished  elapsed time :  15.672501150998869\n",
      "iter :  21  starting... finished  elapsed time :  16.040581152003142\n",
      "iter :  22  starting... finished  elapsed time :  15.76496068599954\n",
      "iter :  23  starting... finished  elapsed time :  16.477015763000963\n",
      "iter :  24  starting... finished  elapsed time :  15.857370000998344\n",
      "iter :  25  starting... finished  elapsed time :  15.888926068000728\n",
      "iter :  26  starting... finished  elapsed time :  16.022505558001285\n",
      "iter :  27  starting... finished  elapsed time :  16.37827261199709\n",
      "iter :  28  starting... finished  elapsed time :  16.295916553001007\n",
      "iter :  29  starting... finished  elapsed time :  16.147098336001363\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "models= []\n",
    "preds = []\n",
    "\n",
    "for i in range(30):\n",
    "    print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = learn(x_train, y_train, params, np.random.randint(2143486417,high=None))\n",
    "    pred = model.predict(x_eval)\n",
    "    models.append(model)\n",
    "    preds.append(pred)\n",
    "    end = time.perf_counter()\n",
    "    print('finished ', 'elapsed time : ', end-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(preds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_values(x):\n",
    "    return( pd.Series([x.min(), x.max(), x.mean(), x.median(), x.std()]))\n",
    "\n",
    "df[['min', 'max', 'mean','median','std']]=df.apply(calc_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred = pd.concat([Y_eval.reset_index(), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred['mean_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['mean'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['median_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['median'])/Y_eval_pred['keiyaku_pr']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.554185100232068"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_eval_pred['mean_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.42161858338207"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_eval_pred = pd.concat([Y_eval.reset_index(), df], axis=1)\n",
    "Y_eval_pred['mean_error']=abs(Y_eval_pred['keiyaku_pr']-Y_eval_pred['mean'])/Y_eval_pred['keiyaku_pr']*100\n",
    "Y_eval_pred['mean_error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### これで次の提出データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x_v9.csv\")\n",
    "x_test = test_x.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(anss).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=df['mean']\n",
    "submit.to_csv('data/submit_v10.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_evalで再現テストする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = X_eval.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(anss).T\n",
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_eval_pred2=pd.concat([Y_eval.reset_index(), df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_eval_pred2['error']=abs(Y_eval_pred2['keiyaku_pr']-Y_eval_pred2['mean'])/Y_eval_pred2['keiyaku_pr']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.42161858338207"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_eval_pred2['error'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_trainで再現テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = X_train.drop(['id','pj_no'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anss = []\n",
    "\n",
    "for i in range(30):\n",
    "    #print('iter : ', i,' starting...', end=' ')\n",
    "    start = time.perf_counter()\n",
    "    model = models[i]\n",
    "    ans = model.predict(x_test)\n",
    "    anss.append(ans)\n",
    "    end = time.perf_counter()\n",
    "    #print('finished ', 'elapsed time : ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.088302589736845"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(anss).T\n",
    "df['mean']=df.apply( lambda x: int(x.mean()),axis=1)\n",
    "Y_eval_pred2=pd.concat([Y_train.reset_index(), df], axis=1)\n",
    "Y_eval_pred2['error']=abs(Y_eval_pred2['keiyaku_pr']-Y_eval_pred2['mean'])/Y_eval_pred2['keiyaku_pr']*100\n",
    "Y_eval_pred2['error'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "# 事前準備処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v9.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v9.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn( train_x, train_y, params, s ):\n",
    "    model = XGBRegressor(**params, seed=s, n_jobs=-1)\n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v9.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v9.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "## 土地売り・建て売りに分解せずに同じことをしてみる\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "model = learn(X_train.drop(['id','pj_no'],axis=1), Y_train.drop(['id'],axis=1), params, 42)\n",
    "pred_y = model.predict(X_eval.drop(['id','pj_no'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_all = pd.DataFrame(X_eval[['id','levelplan_土地売り']].copy().reset_index(drop=True))\n",
    "Y_pred_all['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.58929204425\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_percentage_error(Y_eval_pred['keiyaku_pr'].values, Y_eval_pred['pred_keiyaku_pr'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keiyaku_pr</th>\n",
       "      <th>levelplan_土地売り</th>\n",
       "      <th>pred_keiyaku_pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1255</td>\n",
       "      <td>21700000</td>\n",
       "      <td>0</td>\n",
       "      <td>24113422.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_2319</td>\n",
       "      <td>26300000</td>\n",
       "      <td>0</td>\n",
       "      <td>28799550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_4409</td>\n",
       "      <td>30000000</td>\n",
       "      <td>0</td>\n",
       "      <td>32914426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_5358</td>\n",
       "      <td>36800000</td>\n",
       "      <td>0</td>\n",
       "      <td>32592012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4592</td>\n",
       "      <td>21000000</td>\n",
       "      <td>0</td>\n",
       "      <td>26503988.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  keiyaku_pr  levelplan_土地売り  pred_keiyaku_pr\n",
       "0  train_1255    21700000               0       24113422.0\n",
       "1  train_2319    26300000               0       28799550.0\n",
       "2  train_4409    30000000               0       32914426.0\n",
       "3  train_5358    36800000               0       32592012.0\n",
       "4  train_4592    21000000               0       26503988.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_eval_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Y_eval_pred\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/processed_train_goto_x_v9.csv\"),on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"data/tmp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以降はむだだったコード。建て売りか土地売りかで別モデルを作ったが、結局意味はなかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 土地売りと建て売りとにデータを分割\n",
    "X_train_tateuri = X_train[X_train['levelplan_土地売り']==0]\n",
    "X_train_tochiuri = X_train[X_train['levelplan_土地売り']==1]\n",
    "Y_train_tateuri = Y_train[X_train['levelplan_土地売り']==0]\n",
    "Y_train_tochiuri = Y_train[X_train['levelplan_土地売り']==1]\n",
    "\n",
    "X_eval_tateuri = X_eval[X_eval['levelplan_土地売り']==0]\n",
    "X_eval_tochiuri = X_eval[X_eval['levelplan_土地売り']==1]\n",
    "Y_eval_tateuri = Y_eval[X_eval['levelplan_土地売り']==0]\n",
    "Y_eval_tochiuri = Y_eval[X_eval['levelplan_土地売り']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 土地売り以外のlevelplanを削除してみる\n",
    "X_train_1 = X_train.drop(['levelplan_1F/2LDK','levelplan_1F/3LDK','levelplan_1F/4LDK','levelplan_1F/4LDK+S','levelplan_1F/5LDK'],axis=1)\n",
    "X_train_2 = X_train_1.drop(['levelplan_2F/2LDK','levelplan_2F/2LDK+S','levelplan_2F/3DK','levelplan_2F/3LDK','levelplan_2F/3LDK+2S','levelplan_2F/3LDK+S','levelplan_2F/4DK','levelplan_2F/4LDK','levelplan_2F/4LDK+S','levelplan_2F/5DK','levelplan_2F/5LDK'],axis=1)\n",
    "X_train_3 = X_train_2.drop(['levelplan_3F/2LDK','levelplan_3F/2LDK+2S','levelplan_3F/2LDK+S','levelplan_3F/3DK','levelplan_3F/3LDK','levelplan_3F/3LDK+2S','levelplan_3F/3LDK+S','levelplan_3F/4DK','levelplan_3F/4LDK','levelplan_3F/4LDK+S','levelplan_3F/5LDK'],axis=1)\n",
    "\n",
    "X_eval_1 = X_eval.drop(['levelplan_1F/2LDK','levelplan_1F/3LDK','levelplan_1F/4LDK','levelplan_1F/4LDK+S','levelplan_1F/5LDK'],axis=1)\n",
    "X_eval_2 = X_eval_1.drop(['levelplan_2F/2LDK','levelplan_2F/2LDK+S','levelplan_2F/3DK','levelplan_2F/3LDK','levelplan_2F/3LDK+2S','levelplan_2F/3LDK+S','levelplan_2F/4DK','levelplan_2F/4LDK','levelplan_2F/4LDK+S','levelplan_2F/5DK','levelplan_2F/5LDK'],axis=1)\n",
    "X_eval_3 = X_eval_2.drop(['levelplan_3F/2LDK','levelplan_3F/2LDK+2S','levelplan_3F/2LDK+S','levelplan_3F/3DK','levelplan_3F/3LDK','levelplan_3F/3LDK+2S','levelplan_3F/3LDK+S','levelplan_3F/4DK','levelplan_3F/4LDK','levelplan_3F/4LDK+S','levelplan_3F/5LDK'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習ルーチンを呼び出す。\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "tateuri_model = learn(X_train_tateuri.drop(['id','pj_no','levelplan_土地売り'],axis=1), Y_train_tateuri.drop(['id'],axis=1), params, 42)\n",
    "tochiuri_model = learn(X_train_tochiuri.drop(['id','pj_no','levelplan_土地売り'],axis=1), Y_train_tochiuri.drop(['id'],axis=1), params, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 予測する\n",
    "pred_y_tateuri = tateuri_model.predict(X_eval_tateuri.drop(['id','pj_no','levelplan_土地売り'],axis=1))\n",
    "pred_y_tochiuri = tochiuri_model.predict(X_eval_tochiuri.drop(['id','pj_no','levelplan_土地売り'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataFrameの形で予測値を作成する\n",
    "Y_pred_tateuri = pd.DataFrame(X_eval_tateuri['id'].copy().reset_index(drop=True))\n",
    "Y_pred_tateuri['pred_keiyaku_pr'] = pd.Series(pred_y_tateuri)\n",
    "Y_pred_tochiuri = pd.DataFrame(X_eval_tochiuri['id'].copy().reset_index(drop=True))\n",
    "Y_pred_tochiuri['pred_keiyaku_pr'] = pd.Series(pred_y_tochiuri)\n",
    "Y_pred_all = pd.concat([Y_pred_tateuri, Y_pred_tochiuri])\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = learn(X_train_3.drop(['id','pj_no'],axis=1), Y_train.drop(['id'],axis=1), params, 42)\n",
    "pred_y = model.predict(X_eval_3.drop(['id','pj_no'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_all = pd.DataFrame(X_eval_3[['id','levelplan_土地売り']].copy().reset_index(drop=True))\n",
    "Y_pred_all['pred_keiyaku_pr'] = pd.Series(pred_y)\n",
    "Y_eval_pred = pd.merge(Y_eval, Y_pred_all, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.56302858604\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_percentage_error(Y_eval_pred['keiyaku_pr'].values, Y_eval_pred['pred_keiyaku_pr'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start learning...\n",
      "26.849811518000024\n",
      "start estimating...\n",
      "[ 3.48094355]\n"
     ]
    }
   ],
   "source": [
    "# 共通処理\n",
    "# x_train. y_train, x_eval, y_evalを作成する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mean_absolute_percentage_error( y_train: np.array, y_pred: np.array):\n",
    "    diff = 0\n",
    "    n = len(y_train)\n",
    "    for i in range(n):\n",
    "        diff += abs(y_train[i]-y_pred[i])/y_train[i]\n",
    "    score = 100*diff / n\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "train_x = pd.read_csv(\"data/processed_train_goto_x_v8.csv\")\n",
    "train_y = pd.read_csv(\"data/processed_train_goto_y_v8.csv\")\n",
    "X_train, X_eval, Y_train, Y_eval = train_test_split( train_x, train_y, train_size=0.8, random_state = 19711022)\n",
    "\n",
    "X_train.to_csv(\"data/X_train.csv\", index=False)\n",
    "X_eval.to_csv(\"data/X_eval.csv\", index=False)\n",
    "Y_train.to_csv(\"data/Y_train.csv\", index=False)\n",
    "Y_eval.to_csv(\"data/Y_eval.csv\", index=False)\n",
    "\n",
    "train_x = pd.read_csv('data/X_train.csv').drop(['id','pj_no'],axis=1)\n",
    "train_y = pd.read_csv('data/Y_train.csv').drop(['id'],axis=1)\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "import time\n",
    "\n",
    "params = {\n",
    "    'n_estimators':700,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':9,\n",
    "    'gamma':0,\n",
    "    'subsample':1.0,\n",
    "    'colsample_bytree':0.6,\n",
    "    'learning_rate':0.1\n",
    "}\n",
    "\n",
    "print(f\"start learning...\")\n",
    "xgboost_opt = XGBRegressor(**params, seed=42, n_jobs=-1)\n",
    "start = time.perf_counter()\n",
    "xgboost_opt.fit(train_x, train_y)\n",
    "end = time.perf_counter()\n",
    "print(end-start)\n",
    "\n",
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/processed_train_goto_x_v8.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/processed_train_goto_y_v8.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/processed_train_goto_y_v8.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/processed_train_goto_x_v8.csv\"),on='id')\n",
    "output.to_csv(\"data/train_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start estimating...\n",
      "[ 8.70952682]\n"
     ]
    }
   ],
   "source": [
    "print(f\"start estimating...\")\n",
    "eval_x = pd.read_csv('data/X_eval.csv').drop(['id','pj_no'],axis=1)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id'],axis=1)\n",
    "pred_y = xgboost_opt.predict(eval_x)\n",
    "print( mean_absolute_percentage_error(ans_y.values,pred_y))\n",
    "\n",
    "out = pd.read_csv('data/Y_eval.csv')\n",
    "out['pred_keiyaku_pr'] = pd.Series(pred_y).astype(np.int64)\n",
    "out['error']=abs((out['keiyaku_pr']-out['pred_keiyaku_pr'])/out['keiyaku_pr'])*100\n",
    "output = pd.merge(out, pd.read_csv(\"data/X_eval.csv\"),on='id')\n",
    "output.to_csv(\"data/eval_data_error.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(xgboost_opt.feature_importances_, index=eval_x.columns)\n",
    "importance.to_csv(\"data/feature_importances_V8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x_v8.csv\")\n",
    "test_pred = xgboost_opt.predict(test_x.drop(['id','pj_no'],axis=1))\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(test_pred).astype(np.int64)\n",
    "submit.to_csv('data/submit_v8.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n_estimatorsが700のケースでsubmitしてみることにする(7/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")\n",
    "test_pred = xgboost_opt.predict(test_x.drop(['id','pj_no'],axis=1))\n",
    "submit = pd.DataFrame(test_x[['id']])\n",
    "submit['keiyaku_pr']=pd.Series(test_pred).astype(np.int64)\n",
    "submit.to_csv('data/submit4.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここからSageMaker用のデータを作る処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('data/X_train.csv')\n",
    "train_y = pd.read_csv('data/Y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_input = pd.concat([train_y.drop(['id','keiyaku_pr','tc_mseki'],axis=1),train_x.drop(['id','pj_no'],axis=1)],axis=1)\n",
    "train_input.to_csv('data/sagemaker_input.csv', header=None, index=False)\n",
    "eval_x = pd.read_csv('data/X_eval.csv')\n",
    "eval_x.drop(['id','pj_no'],axis=1).to_csv('data/sagemaker_eval_input.csv',header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMakerの出力から精度を計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2_y = pd.read_csv('data/sagemaker_eval_input.csv.out', header=None)\n",
    "ans_y = pd.read_csv('data/Y_eval.csv').drop(['id','keiyaku_pr','tc_mseki'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( mean_absolute_percentage_error(ans_y.values,pred2_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SageMaker用予測データを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_input = test_x.drop(['id','pj_no'],axis=1)\n",
    "test_input.to_csv('data/sagemaker_test_input.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker出力からsubmit用データを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tanka = pd.read_csv(\"data/sagemaker_test_input.csv.out\", header=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.read_csv(\"data/processed_test_goto_x.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(test_x[['id', 'tc_mseki']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['tanka_pr']=tanka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit['price']=(submit['tc_mseki']*submit['tanka_pr']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.loc[:,['id','price']].to_csv('data/submit3.tsv',sep='\\t',header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
